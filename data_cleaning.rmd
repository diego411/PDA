---
title: "Data Cleaning"
output: github_document
---

# Data Cleaning

Load required packages.

```{r load packages, warning=FALSE, message=FALSE}

library( tidyverse )
library( dplyr )
library( gridExtra )

```

Set up workspace, i.e., remove all existing data from working memory and load data from CSV file.

```{r setup}

rm( list=ls() )
df <- read.csv("C:/Users/Luisa/OneDrive/!Master Social Research/23W/Programming for Data Analytics/R/Airbnb/airbnb_data.csv")

```

# Transform data

Convert the room_type, neighborhood_group, and neighborhood variables into factors and the last_review variable into a Date object.

```{r}

head(df)
df <- df %>%
  mutate(
    room_type = as.factor(room_type),
    neighbourhood_group = as.factor(neighbourhood_group),
    neighbourhood = as.factor(neighbourhood),
    last_review=as.Date(last_review, format = "%Y-%m-%d")
  )

str(df)

```


# Missing values

Count the number of missing values and calculate the percentage.
 
```{r}

empty_values <- c(NA, NULL, "", " ")

get_na_summary <- function(df) {
  nrows = nrow(df)
  NAs <- data.frame()

  for (column_name in colnames(df)) {
    na_count <- sum(df[[column_name]] %in% empty_values)#is.na(df[[column_name]]))
    row <- data.frame(
      variable = column_name,
      na_count = na_count,
      na_percent = round(na_count / nrows, 4) 
    )
    NAs <- rbind(NAs, row)
  }

  return(NAs)
}

get_na_summary(df)

```

Defining a function to filter out rows where variables contain missing values.
Missing values in reviews_per_month are replaced with 0, assuming no review means zero reviews per month. 
Keep only rows without empty values in the name and host_name variables.
Check the dataframe again for missing values after the cleaning.

```{r}

`%nin%` = Negate(`%in%`)

df <- df %>%
  mutate(reviews_per_month = ifelse(is.na(reviews_per_month), 0, reviews_per_month)) %>%
  filter(name %nin% empty_values) %>%
  filter(host_name %nin% empty_values)

get_na_summary(df)

```

# Feature Engineering

Create a variable that adds the most recent review date available in the dataset and store it in latest_review.

```{r}

latest_review <- df %>%
  filter(!is.na(last_review)) %>%
  summarise(max(last_review))
latest_review <- latest_review[1,]

```

Create a variable that contains the distance to the "center" of New York in Manhattan, here defined as the Columbus Circle.

```{r}
center_latitude <- 40.767811385445356
center_longitude <- -73.98156481716236

manhatten_distance <- function(x1, y1, x2, y2) {
  return(abs(x1 - x2) + abs(y1 - y2))  
}

```

Create a variable that indicates the time passed since the last review. Another variable reflects the distance from the Columbus Circle in Manhattan.
Add both to the dataframe.

```{r}

df <- df %>%
  mutate(
    last_review_age = latest_review - last_review,
    distance_from_center = manhatten_distance(center_latitude, center_longitude, latitude, longitude)  
  )

head(df)

```

Generate kernel density estimates for each variable in the dataframe to assess their distributions.

```{r}

plot_distributions <- function(df) {
  plots <- lapply(names(df), function(var) {
    ggplot(df, aes(x = df[[var]])) +
      geom_density() + # You can also use geom_histogram() for histograms
      labs(title = var)
  })
  grid.arrange(grobs = plots, ncol = 2)
}

df_sample <- df %>%
  select(latitude, longitude, price, number_of_reviews, reviews_per_month, calculated_host_listings_count,  distance_from_center)

plot_distributions(df_sample)

```

Log transforme skewed distributions.

```{r}

df_log <- df %>%
  mutate(
    log_price = log(price),
    log_number_of_reviews = log(number_of_reviews),
    log_reviews_per_month = log(reviews_per_month),
    log_calculated_host_listings_count = log(calculated_host_listings_count)
  )

df_sample <- df_log %>%
  select(
    latitude, longitude, log_price, log_number_of_reviews, log_reviews_per_month, log_calculated_host_listings_count, distance_from_center
  )

plot_distributions(df_sample)

```

Save the modified data to the dataframe.

```{r}

df <- df_log

```


Bin price and check the distribution across bins.

```{r}
bins <- c(0, 50, 100, 200, 500, 1000, 10000)
labels <- c("0-50", "51-100", "101-200", "201-500", "501-1000", "1001+")
df$price_bin <- cut(df$price, breaks = bins, labels = labels, include.lowest = TRUE, right = FALSE)
table(df$price_bin)
barplot(table(df$price_bin), main="Distribution of Price Bins", xlab="Price Bins", ylab="Frequency")
```
The listings are distributed across the bins, though there is less data for the two highest price categories.
Most listings are in bins 2 and 3, i.e., between $51 and $500. The adjacent bins 1 and 4 are also well-represented.



# Consistency

## Min/max

Summarize the data.

```{r}

df_numeric <- df %>%
  select(
    latitude, longitude, price, minimum_nights, number_of_reviews, last_review, reviews_per_month, 
    calculated_host_listings_count, availability_365, last_review_age, distance_from_center
  )

summary(df_numeric)

```

All numeric variables (except longitude) have non-negative values. Max for availability_365 is 365.

Price: Minimum value of 0, likely indicating missing data rather than actual free listings.
Minimum Nights: A maximum of 1250 nights suggests potential outliers.

Check entries with price equal to 0.

```{r}
df[df$price == 0, ]
```

All but one listing have a non-zero number of reviews, which suggests they are legitimate listings.
All but one listing have non-null values for reviews_per_month, indicating recent activity.
Most listings have availability days (availability_365 > 0), indicating that they can be booked.

Replace $0 listings with NA assuming they represent missing data and exclude one implausible listing.

```{r}

df$price[df$price == 0] <- NA
df <- df[!(df$price == 0 & df$id == 20933849), ]

```


## Unique ids

Compare the number of rows and the number of unique ids to determine whether each row has a unique identifier.

```{r}

length_df <- nrow(df)
unique_ids <- length(unique(df$id))

length_df == unique_ids

```
There are no id inconsistencies.

## Reviews

Filter the dataframe to find entries where reviews_per_month is 0 but number_of_reviews is not 0, find entries with 0 number_of_reviews but a non-NA last_review date and identify rows where reviews_per_month is 0 but last_review is not NA.

```{r}

result <- df %>%
  filter(
    reviews_per_month == 0, 
    number_of_reviews != 0
  )

nrow(result)

result <- df %>%
  filter(
    number_of_reviews == 0,
    !is.na(last_review)
  )

nrow(result)

result <- df %>%
  filter(
    reviews_per_month == 0,
    !is.na(last_review)
  )

nrow(result)

```
All review variables are internally consistent.

# Duplicates

Find duplicates based on the id column and identify listings that are at the exact same location.

```{r}

duplicates_by_id <- df[duplicated(df$id), 1]
duplicates_by_id  

duplicates_by_host_id_and_name <- df[duplicated(df$latitude, df$longitude), ]
duplicates_by_host_id_and_name
?duplicated

df[!(duplicated(df[c("longitude","latitude")]) | duplicated(df[c("longitude","latitude")], fromLast = TRUE)), ] %>%
  select(latitude, longitude)

df %>%
  distinct(longitude, latitude, .keep_all = TRUE)

df %>%
  distinct(round(longitude, 8), round(latitude, 8), .keep_all = TRUE) %>%
  select(longitude, latitude)

str(df)

df %>%
  filter(latitude == 40.75362	)#, longitude == -73.97237	)

View(df)

```

Listings in the same location could be apartments in the same building complex.
