---
title: "Data Cleaning"
output: github_document
---

Load required packages.

```{r load packages, warning=FALSE, message=FALSE}

library( tidyverse )
library( dplyr )
library( gridExtra )
library( ggmap )
library( geosphere )
library( cld2 )

```

Set up workspace, i.e., remove all existing data from working memory and load data from CSV file.

```{r setup}

rm( list=ls() )
df <- read.csv("./data/airbnb_data.csv")

```


# Data Overview
The dataset contains information related to Airbnb listings in New York City. Each row in the dataset corresponds to a unique listing with its own identifier and has associated attributes like the type of room, neighborhood details, price, reviews, and the physical coordinates of the listing. Also provided are the name of the listing and the host's name as given on the Airbnb platform as well as how many listings each hosts entertains in total and for how many days each listing is available in a year.

## Dataset Size
```{r}
cat(paste("Total number of listings:", nrow(df)), "\n")
cat(paste("Total number of unique hosts:", length(unique(df$host_id))), "\n")
```
The dataset contains a total of 48,843 listings. These listings come from 37,420 unique hosts. This suggests that while many hosts have a single listing, there's a considerable number of hosts with multiple listings.


## Time Span Covered

```{r}
cat(paste("Earliest review date:", min(df$last_review, na.rm = TRUE)), "\n")
cat(paste("Latest review date:", max(df$last_review, na.rm = TRUE)), "\n")
cat(paste("Time span covered:", 
          as.numeric(difftime(max(as.Date(df$last_review), na.rm = TRUE), 
                              min(as.Date(df$last_review), na.rm = TRUE), units = "days")), "days"), "\n")
```
The dataset spans over a period of 3,024 days, i.e., approximately 8.3 years. The earliest review date on record is March 28, 2011, the latest review is from July 8, 2019. 


## Descriptive Statistics of Continuous Variables
```{r}
# Summary statistics
summary(df[,c('price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365')])

# Price
cat(paste("Average price:", round(mean(df$price, na.rm = TRUE), 2)), "\n")

# Minimum Nights
cat(paste("Average minimum nights:", 
          round(mean(df$minimum_nights, na.rm = TRUE), 2)), "\n")

# Listing Activity Overview
active_listings_past_year <- 
cat(paste("Number of listings with reviews in the past year:", 
          sum(df$last_review > as.Date(df$latest_review) - 365, na.rm = TRUE)), "\n")

# Host Overview
listings_per_host <- table(df$host_id)
multiple_listings_hosts <- sum(listings_per_host > 1)

cat(paste("Number of hosts with multiple listings:", multiple_listings_hosts), "\n")
```

The price of listings varies widely, ranging from $0 listings to luxurious options priced at $10,000. On average, a guest can expect to pay around $152.8 per night, with half of the listings priced at or below $106.

The minimum nights required by hosts shows a broad spread as well, though the typical (median) stay requirement is just 3 nights. On average, listings require stays of about a week (7 nights). This indicates that while most hosts are looking for short to medium-term stays, there are a few outliers.

As for guest feedback, some listings have yet to be reviewed, while others have as many as 629 reviews. The average listing has been reviewed about 23 times. This diversity in reviews shows the variance of listing popularity and guest traffic.

At least 50 % of hosts offer only one listing, with some hosts offering up to 327 apartments in NYC. 

Listings are in part not available for rent at all, the median availability is 45 days out of the 365 days in a year.

## Location
```{r}
cat("Number of unique neighbourhood groups:", 
    length(unique(df$neighbourhood_group)), "\n")

cat(paste("Number of unique neighbourhoods:", 
          length(unique(df$neighbourhood))), "\n")

# Top neighbourhoods
top_neighbourhoods <- head(sort(table(df$neighbourhood), decreasing = TRUE), 5)
cat("Top 5 neighbourhoods by number of listings:\n")
print(top_neighbourhoods)

# Least popular neighbourhoods
bottom_neighbourhoods <- head(sort(table(
  df$neighbourhood), decreasing = FALSE), 5)

cat("Bottom 5 neighbourhoods by number of listings:\n")
print(bottom_neighbourhoods)

# Listings by neighbourhood group
cat("Number of listings by Neighbourhood Group:\n")
table(df$neighbourhood_group)

# Listings by room type
cat("Number of listings by Room Type:\n")
table(df$room_type)

# Bar plot of listings by neighbourhood group:
df %>% 
  filter(!is.na(neighbourhood_group)) %>% 
  ggplot(aes(x = neighbourhood_group)) + 
  geom_bar() + 
  labs(
    title = "Listings by Neighbourhood Group", 
    x = "Neighbourhood Group", 
    y = "Frequency"
  )

# Heat map of listings
ggplot(df, aes(x=longitude, y=latitude)) + 
  geom_density_2d_filled(show.legend = TRUE, aes(fill = ..level..)) + 
  coord_cartesian(xlim = c(-74.08, -73.85), ylim = c(40.64, 40.86)) + 
  labs(title="Density Heatmap of Listings", x="Longitude", y="Latitude")

```

Location plays a vital role in the dataset. The top 5 neighbourhoods feature up to 3,917 listings, while the least popular neighbourhoods only have one listing. Most listings in the dataset are in Manhattan and Brooklyn.

The majority of the listings are for entire homes/apartments (25,393), followed by private rooms (22,306), and a relatively smaller number are shared rooms (1,159).

## Room types
```{r}
cat("Number of unique room types:", length(unique(df$room_type)), "\n")

# Distribution of Room Type
df %>% 
  filter(!is.na(neighbourhood_group)) %>% 
  ggplot(aes(x=room_type)) + 
  geom_bar() + 
  labs(title="Distribution of Room Types", x="Room Type", y="Frequency")

# Geographic distribution of private room vs. apartment
df %>% 
  filter(room_type %in% c('Private room', 'Entire home/apt')) %>% 
  ggplot(aes(x = longitude, y = latitude, color = room_type)) + 
  geom_point() + 
  scale_color_manual(values = c("Private room" = "blue", 
                                "Entire home/apt" = "red")) +
  labs(title = "Geographic Distribution of 'Private Room' vs. 'Entire home/apt'",
       x = "Longitude", 
       y = "Latitude",
       color = "Room Type")

# Bar plot of Room Types by location
df %>% 
  filter(!is.na(neighbourhood_group)) %>% 
  ggplot(aes(x=neighbourhood_group, fill=room_type)) + 
  geom_bar(position="dodge") +
  labs(title="Distribution of Room Types by Neighbourhood Group", 
       x="Neighborhood", 
       y="Frequency")

```

Only few listing are of a shared room. 

Listings for an entire home/apt are more expensive, followed by private and shared rooms.

In Manhattan, most listings are for an entire home/apartment, while in other neighborhoods, private rooms dominate. Brooklyn stands out as a balanced neighborhood with almost equal representation of both types.


## Listing Activity
```{r}
cat(paste("Number of listings with reviews in the past year:", sum(df$last_review > as.Date(df$latest_review) - 365, na.rm = TRUE)), "\n")
```
Out of the entire dataset, 29,118 listings have had a review in the past year. This suggests that a considerable number of listings are active and have had recent guests.

# Transform data

Convert the room_type, neighborhood_group, and neighborhood variables into factors and the last_review variable into a Date object.

```{r}

head(df)
df <- df %>%
  mutate(
    room_type = as.factor(room_type),
    neighbourhood_group = as.factor(neighbourhood_group),
    neighbourhood = as.factor(neighbourhood),
    last_review=as.Date(last_review, format = "%Y-%m-%d")
  )

str(df)

```


# Missing values

Count the number of missing values and calculate the percentage.
 
```{r}

empty_values <- c(NA, NULL, "", " ")

get_na_summary <- function(df) {
  nrows = nrow(df)
  NAs <- data.frame()

  for (column_name in colnames(df)) {
    na_count <- sum(df[[column_name]] %in% empty_values)#is.na(df[[column_name]]))
    row <- data.frame(
      variable = column_name,
      na_count = na_count,
      na_percent = round(na_count / nrows, 4) 
    )
    NAs <- rbind(NAs, row)
  }

  return(NAs)
}

get_na_summary(df)

```

Defining a function to filter out rows where variables contain missing values.
Missing values in reviews_per_month are replaced with 0, assuming no review means zero reviews per month. 
Keep only rows without empty values in the name and host_name variables.
Check the dataframe again for missing values after the cleaning.

```{r}

`%nin%` = Negate(`%in%`)

df <- df %>%
  mutate(reviews_per_month = ifelse(is.na(reviews_per_month), 0, reviews_per_month)) %>%
  filter(name %nin% empty_values) %>%
  filter(host_name %nin% empty_values)

get_na_summary(df)

```

# Feature Engineering

## Review age

Create a variable that adds the most recent review date available in the dataset and store it in latest_review.

```{r}

latest_review <- df %>%
  filter(!is.na(last_review)) %>%
  summarise(max(last_review))
latest_review <- latest_review[1,]

df <- df %>%
  mutate(
    last_review_age = latest_review - last_review,
  )

head(df)

```

## Price bin

Bin price and check the distribution across bins.

```{r}

bins <- c(0, 50, 100, 200, 500, 1000, 10000)
labels <- c("0-50", "51-100", "101-200", "201-500", "501-1000", "1001+")
df <- df %>%
  mutate(price_bin = cut(price, breaks = bins, labels = labels, include.lowest = TRUE, right = FALSE))

df %>%
  count(price_bin) %>%
  ggplot(aes(x = price_bin, y = n)) +
  geom_col() +
  labs(title="Distribution of Price Bins", x="Price Bins", y="Frequency")

```

The listings are distributed across the bins, though there is less data for the two highest price categories.
Most listings are in bins 2 and 3, i.e., between $51 and $500. The adjacent bins 1 and 4 are also well-represented.

## Name length

This adds a column to the dataframe with the count of characters in a listing's name after having removed the spaces: 

```{r}

#count characters (without " ")
df <- df %>%
  mutate(name_length = nchar(str_replace_all(name, " ", "")))

```

## Name Category

Get average number of characters, median, maximum and minimum:

```{r}

avg_name_length <- mean(df$name_length)
median_name_length <- median(df$name_length)
minimum_name_length <- min(df$name_length)
maximum_name_length <- max(df$name_length)

```
The minimum number of characters is 0, which suggests that there are listings without a name. The mean and median are very close (31,76 to 32) which indicates that the distribution could be (close to) symmetrical. The longest name having 151 characters seems to be an outlier. 

Plot number of characters in histogram using bins of size 15: 

```{r}
bin_labels = seq(0, maximum_name_length, 10)
labels <- paste0("  ",bin_labels, "-", bin_labels + 9, "  ")

df %>%
  ggplot( mapping = aes( x=name_length )) +
  geom_histogram(binwidth = 10)  +
  stat_bin(
    binwidth = 10,
    geom = 'text',
    aes(label = after_stat(count)),
    vjust = -0.5,
    size = 3,
    color = "black"
  ) +
  labs( title = "How long are the names of AirBnB listings?",
        x = "Number of characters in listing's name", 
        y = "Frequency") +
  scale_x_continuous(breaks = bin_labels, labels=labels) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
While there are a few outliers (which we look at below), most names fall between 15 and 59 characters.
Quantile berechnen


Look at the longest names (>75) and the shortest (<15): 

```{r}

df %>% filter(name_length > 60)
df %>% filter(name_length < 10)

```
Shorter names not very informational, while the longer names have almost too much information. 
It could make sense to categorize the length into three bins. 


Make length of name into a factor (short, medium, long): 

```{r}
df <- df %>% 
  mutate(name_category = cut(name_length, 
                        breaks = c(0, 9, 59, 151),
                        labels = c("short", "medium", "long"),
                        include.lowest = TRUE)) %>% mutate(name_category = as.factor(name_category))
```

## Upper Case

Another aspect that might be worth investigating is the use of upper case letters. Manual screening showed that there are some names that only consist of upper case letters which can be perceived as "screaming" on the internet. 

Count the number of upper case letters in a listing's name. Then introduce a new categorical (factor) variable that indicates whether a name consists of only upper case letters (1) or not (0) and get some basic summary statistics about it: 

TODO: Remove !,, and such from name length. There could be all-upper-case names that don't appear in list because they contain punctuation :D

```{r}

df <- df %>%
  mutate(upper_case_count = str_count(name, "[A-Z]"))

df <- df %>% 
  mutate(is_upper_case = ifelse(name_length == upper_case_count, 1, 0)) %>% 
  mutate(is_upper_case = as.factor(is_upper_case))

df %>% 
  filter(is_upper_case == 1)

df %>% 
  count(is_upper_case ==1)

```

There are 554 listings where the name contains upper case letters only. 

## Language

Showed some names in a different language. Let's detect them and see if there is an correlation to the number of reviews: 

```{r}
#install.packages("cld3")

df <- df %>% 
  mutate(name_language = detect_language(text = name)) 
df %>% 
  count(name_language)
df$name_language <- df$name_language %>% replace_na('')

```
38 different languages (37 and NA) were detected, majority english. For ease, since new york listing, we concentrate on the difference between english and no english. 

```{r}

df <- df %>% 
  mutate(is_english = ifelse(name_language == "en", 1, 0)) 

```

## Earnings

Create variable indicating listings average monthly earnings

Note that we assume that every visitor leaves a review as a reputation system
incentivizes users to do so. Note also, that we are only able to calculate
the lowest potential earnings as we have only insight into the minimum number
of nights visitors need to stay.

```{r}

df <- df %>%
  mutate(lowest_monthly_earnings = minimum_nights*reviews_per_month*price)

```

## Distances

```{r}

distance <- function(lat1, long1, lat2, long2) {
  dist <- distGeo(matrix(c(lat1, long1), ncol = 2), matrix(c(lat2, long2), ncol = 2))
  return(dist/1000)
}

manhatten_distance <- function(x1, y1, x2, y2) {
  return(abs(x1 - x2) + abs(y1 - y2))  
}

```

### Distance to center of Manhattan

Create a variable that contains the distance to the "center" of New York in Manhattan, here defined as the Columbus Circle.

```{r}

center_latitude <- 40.767811385445356
center_longitude <- -73.98156481716236

```

```{r}

df <- df %>%
  mutate(
    distance_from_center = manhatten_distance(center_latitude, center_longitude, latitude, longitude)
  )

head(df)

```

### Distance to airports

Build variables with latitude and longitude of several focal points.
We use the three international airports of NY, 3 sigths (Empire State Building, Statue of Liberty, Central Park) and the five centers of every neighbourhood.

```{r}

jfk <- c(latitude = 40.6413, longitude = -73.7781) # Airport jfk
ewr <- c(latitude = 40.6895314, longitude = -74.17446239) # Airport Newark
lga <- c(latitude = 40.7769271, longitude = -73.8739659) # Airport laGuardia

```

Calculate distances between listing and focal point.

```{r}

df <- df %>%
  mutate(
    distance_to_jfk = distance(latitude, longitude, jfk[1], jfk[2]),
    distance_to_ewr = distance(latitude, longitude, ewr[1], ewr[2]),
    distance_to_lga = distance(latitude, longitude, lga[1], lga[2])
  )

```

### Distance to tourist attractions

```{r}

esb <- c(latitude = 40.748817, longitude = -73.985428) # empire state bulding
sol <- c(latitude = 40.689247, longitude = -74.044502) # statue of liberty
cp  <- c(latitude = 40.785091, longitude = -73.968285) # central park

```

```{r}

df <- df %>%
  mutate(
    distance_to_esb = distance(latitude, longitude, esb[1], esb[2]),
    distance_to_sol = distance(latitude, longitude, sol[1], sol[2]),
    distance_to_cp = distance(latitude, longitude, cp[1], cp[2])
  )

```

### Distance to neighbourhood centers

```{r}

c_mh <- c(latitude = 40.776676, longitude = -73.971321) # center Manhattan
c_br <- c(latitude = 40.650002, longitude = -73.949997) # center Brooklyn
c_si <- c(latitude = 40.579021, longitude = -74.151535) # center Staten Island
c_bx <- c(latitude = 40.837048, longitude = -73.865433) # center Bronx
c_qu <- c(latitude = 40.734470, longitude = -73.869720) # center Queens

```

```{r}

df <- df %>%
  mutate(
    distance_to_c_mh = distance(latitude, longitude, c_mh[1], c_mh[2]),
    distance_to_c_br = distance(latitude, longitude, c_br[1], c_br[2]),
    distance_to_c_bx = distance(latitude, longitude, c_bx[1], c_bx[2]),
    distance_to_c_qu = distance(latitude, longitude, c_qu[1], c_qu[2]),
    distance_to_c_si = distance(latitude, longitude, c_si[1], c_si[2])
  )
```

## Log variables

Generate kernel density estimates for each variable in the dataframe to assess their distributions.

```{r}

plot_distributions <- function(df) {
  plots <- lapply(names(df), function(var) {
    ggplot(df, aes(x = df[[var]])) +
      geom_density() + # You can also use geom_histogram() for histograms
      labs(title = var)
  })
  grid.arrange(grobs = plots, ncol = 2)
}

df_sample <- df %>%
  select(latitude, longitude, price, number_of_reviews, reviews_per_month, calculated_host_listings_count,  distance_from_center)

plot_distributions(df_sample)

```

Log transforme skewed distributions.

```{r}

df_log <- df %>%
  mutate(
    log_price = log(price),
    log_number_of_reviews = log(number_of_reviews),
    log_reviews_per_month = log(reviews_per_month),
    log_calculated_host_listings_count = log(calculated_host_listings_count)
  )

df_sample <- df_log %>%
  select(
    latitude, longitude, log_price, log_number_of_reviews, log_reviews_per_month, log_calculated_host_listings_count, distance_from_center
  )

plot_distributions(df_sample)

```

Save the modified data to the dataframe.

```{r}

df <- df_log

```

# Consistency

## Min/max

Summarize the data.

```{r}

df_numeric <- df %>%
  select(
    latitude, longitude, price, minimum_nights, number_of_reviews, last_review, reviews_per_month, 
    calculated_host_listings_count, availability_365, last_review_age, distance_from_center
  )

summary(df_numeric)

```

All numeric variables (except longitude) have non-negative values. Max for availability_365 is 365.


## Price

Price: Minimum value of 0, likely indicating missing data rather than actual free listings.
Minimum Nights: A maximum of 1250 nights suggests potential outliers.

Check entries with price equal to 0.

```{r}

df %>%
  filter(price == 0)

```

Since there are only 11 listings with a price of zero, we assume this is a data gathering error and remove the respective rows.

```{r}

df <- df_non_zero_price <- df %>% 
  filter(price != 0)

```

## Minimum nights

```{r}

max(df$minimum_nights)

```

The maximum for the variable minimum_nights is 1250, meaning that particular listing would have to be rented as a minimum for well over 3 years. This seems excessive as AirBnB in most cases is used for holidays or short to mid stays. We do not see a reason for a host to require the listing to be rented for such a long time and thus will consider it and similar entries as data anomalies.


```{r}

quantile(df$minimum_nights, 0.9999)

```

The minimum required nights is less than 500 for 99.99% of all listing. This number seems more or less reasonable. In the following we will therefore remove all entries that fall above this threshold.

```{r}

df <- df %>%
  filter(minimum_nights <= quantile(minimum_nights, 0.9999))

```


## Unique ids

Compare the number of rows and the number of unique ids to determine whether each row has a unique identifier.

```{r}

length_df <- nrow(df)
unique_ids <- length(unique(df$id))

length_df == unique_ids

```
There are no id inconsistencies.

## Reviews

Filter the dataframe to find entries where reviews_per_month is 0 but number_of_reviews is not 0, find entries with 0 number_of_reviews but a non-NA last_review date and identify rows where reviews_per_month is 0 but last_review is not NA.

```{r}

result <- df %>%
  filter(
    reviews_per_month == 0, 
    number_of_reviews != 0
  )

nrow(result)

result <- df %>%
  filter(
    number_of_reviews == 0,
    !is.na(last_review)
  )

nrow(result)

result <- df %>%
  filter(
    reviews_per_month == 0,
    !is.na(last_review)
  )

nrow(result)

```
All review variables are internally consistent.

# Duplicates

Find duplicates based on the id column and identify listings that are at the exact same location.

```{r}

get_duplicates_by_columns <- function(df, column_names) {
  column_indexes <- unlist(lapply(column_names, function(name) {
    return (grep(name, colnames(df)))
  })) 
  
  return (df[duplicated(df[,column_indexes]) | duplicated(df[,column_indexes], fromLast = TRUE),])
}

```

## Duplicate ids

```{r}

nrow(get_duplicates_by_columns(df, c("id")))

```
## Duplicate names

```{r}

get_duplicates_by_columns(df, c("name")) %>%
  select(id, name, host_name, neighbourhood, price) %>%
  arrange(desc(name))

```
There are a lot of duplicate names in the dataset. Most of the time these listings seem to be from the same host. However, the listings seem to always differ in the neighbourhood or in the price. This will be further analysed in the following.

```{r}

get_duplicates_by_columns(df, c("name", "latitude", "longitude")) %>%
  select(id, name, host_name, price, latitude, longitude) %>%
  arrange(desc(name))

```

As one can see there are no listings with the same name that are also at the same geographic position. Since the combination of name, latitude and longitude is already a super key differentiating every row, no furher supersets of this combination need to be analysed.

## Duplicate positions

```{r}

get_duplicates_by_columns(df, c("longitude", "latitude")) %>%
  select(id, name, host_name, longitude, latitude) %>%
  arrange(desc(latitude))

```
There are some listings that are at the exact same position. However, they more often than not have a different host or name and in every case a different price. Thus, we will not drop these entries and consider them in our analysis.

# Export

```{r}

write.csv(df, "./data/airbnb_clean.csv")

```

