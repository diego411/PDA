---
output:
  html_document: default
  pdf_document: default
---
# AirBnb

Load required packages.

```{r load packages, warning=FALSE, message=FALSE}

library( tidyverse )
library( dplyr )
library( gridExtra )
library( ggridges )
library( mapview )
library( leaflet )
library( leaflet.extras )
library( scales )
library( stargazer )
library( GGally )
library( corrplot )
library( tm )
library( wordcloud )
library( broom )
library( Hmisc )
library( geosphere )
require( gender )
require( tidytext )
library( ggmap )
library( geosphere )
library( cld2 )
library(knitr)

```

Set up workspace, i.e., remove all existing data from working memory and load data from CSV file.

```{r setup}

rm( list=ls() )
df <- read.csv("./data/airbnb_data.csv")

```

# Data Overview
The dataset contains information related to Airbnb listings in New York City. Each row in the dataset corresponds to a unique listing with its own identifier and has associated attributes like the type of room, neighborhood details, price, reviews, and the physical coordinates of the listing. Also provided are the name of the listing and the host's name as given on the Airbnb platform as well as how many listings each hosts entertains in total and for how many days each listing is available in a year.

## Dataset Size
```{r}
cat(paste("Total number of listings:", nrow(df)), "\n")
cat(paste("Total number of unique hosts:", length(unique(df$host_id))), "\n")
```
The dataset contains a total of 48,843 listings. These listings come from 37,420 unique hosts. This suggests that while many hosts have a single listing, there's a considerable number of hosts with multiple listings.


## Time Span Covered

```{r}
cat(paste("Earliest review date:", min(df$last_review, na.rm = TRUE)), "\n")
cat(paste("Latest review date:", max(df$last_review, na.rm = TRUE)), "\n")
cat(paste("Time span covered:", 
          as.numeric(difftime(max(as.Date(df$last_review), na.rm = TRUE), 
                              min(as.Date(df$last_review), na.rm = TRUE), units = "days")), "days"), "\n")
```
The dataset spans over a period of 3,024 days, i.e., approximately 8.3 years. The earliest review date on record is March 28, 2011, the latest review is from July 8, 2019. 


## Descriptive Statistics of Continuous Variables
```{r}
# Summary statistics
summary(df[,c('price', 'minimum_nights', 'number_of_reviews', 'reviews_per_month', 'calculated_host_listings_count', 'availability_365')])

# Price
cat(paste("Average price:", round(mean(df$price, na.rm = TRUE), 2)), "\n")

# Minimum Nights
cat(paste("Average minimum nights:", 
          round(mean(df$minimum_nights, na.rm = TRUE), 2)), "\n")

# Listing Activity Overview
active_listings_past_year <- 
cat(paste("Number of listings with reviews in the past year:", 
          sum(df$last_review > as.Date(df$latest_review) - 365, na.rm = TRUE)), "\n")

# Host Overview
listings_per_host <- table(df$host_id)
multiple_listings_hosts <- sum(listings_per_host > 1)

cat(paste("Number of hosts with multiple listings:", multiple_listings_hosts), "\n")
```

The price of listings varies widely, ranging from $0 listings to luxurious options priced at $10,000. On average, a guest can expect to pay around $152.8 per night, with half of the listings priced at or below $106.

The minimum nights required by hosts shows a broad spread as well, though the typical (median) stay requirement is just 3 nights. On average, listings require stays of about a week (7 nights). This indicates that while most hosts are looking for short to medium-term stays, there are a few outliers.

As for guest feedback, some listings have yet to be reviewed, while others have as many as 629 reviews. The average listing has been reviewed about 23 times. This diversity in reviews shows the variance of listing popularity and guest traffic.

At least 50 % of hosts offer only one listing, with some hosts offering up to 327 apartments in NYC. 

Listings are in part not available for rent at all, the median availability is 45 days out of the 365 days in a year.

## Location
```{r warning=FALSE, message=FALSE}
cat("Number of unique neighbourhood groups:", 
    length(unique(df$neighbourhood_group)), "\n")

cat(paste("Number of unique neighbourhoods:", 
          length(unique(df$neighbourhood))), "\n")

# Top neighbourhoods
top_neighbourhoods <- head(sort(table(df$neighbourhood), decreasing = TRUE), 5)
cat("Top 5 neighbourhoods by number of listings:\n")
print(top_neighbourhoods)

# Least popular neighbourhoods
bottom_neighbourhoods <- head(sort(table(
  df$neighbourhood), decreasing = FALSE), 5)

cat("Bottom 5 neighbourhoods by number of listings:\n")
print(bottom_neighbourhoods)

# Listings by neighbourhood group
cat("Number of listings by Neighbourhood Group:\n")
table(df$neighbourhood_group)

# Listings by room type
cat("Number of listings by Room Type:\n")
table(df$room_type)

# Bar plot of listings by neighbourhood group:
df %>% 
  filter(!is.na(neighbourhood_group)) %>% 
  ggplot(aes(x = neighbourhood_group)) + 
  geom_bar() + 
  labs(
    title = "Listings by Neighbourhood Group", 
    x = "Neighbourhood Group", 
    y = "Frequency"
  )

# Heat map of listings
ggplot(df, aes(x=longitude, y=latitude)) + 
  geom_density_2d_filled(show.legend = TRUE, aes(fill = ..level..)) + 
  coord_cartesian(xlim = c(-74.08, -73.85), ylim = c(40.64, 40.86)) + 
  labs(title="Density Heatmap of Listings", x="Longitude", y="Latitude")

```

Location plays a vital role in the dataset. The top 5 neighbourhoods feature up to 3,917 listings, while the least popular neighbourhoods only have one listing. Most listings in the dataset are in Manhattan and Brooklyn.

The majority of the listings are for entire homes/apartments (25,393), followed by private rooms (22,306), and a relatively smaller number are shared rooms (1,159).

## Room types
```{r}
cat("Number of unique room types:", length(unique(df$room_type)), "\n")

# Distribution of Room Type
df %>% 
  filter(!is.na(neighbourhood_group)) %>% 
  ggplot(aes(x=room_type)) + 
  geom_bar() + 
  labs(title="Distribution of Room Types", x="Room Type", y="Frequency")

# Geographic distribution of private room vs. apartment
df %>% 
  filter(room_type %in% c('Private room', 'Entire home/apt')) %>% 
  ggplot(aes(x = longitude, y = latitude, color = room_type)) + 
  geom_point() + 
  scale_color_manual(values = c("Private room" = "blue", 
                                "Entire home/apt" = "red")) +
  labs(title = "Geographic Distribution of 'Private Room' vs. 'Entire home/apt'",
       x = "Longitude", 
       y = "Latitude",
       color = "Room Type")

# Bar plot of Room Types by location
df %>% 
  filter(!is.na(neighbourhood_group)) %>% 
  ggplot(aes(x=neighbourhood_group, fill=room_type)) + 
  geom_bar(position="dodge") +
  labs(title="Distribution of Room Types by Neighbourhood Group", 
       x="Neighborhood", 
       y="Frequency")

```

Only few listing are of a shared room. 

Listings for an entire home/apt are more expensive, followed by private and shared rooms.

In Manhattan, most listings are for an entire home/apartment, while in other neighborhoods, private rooms dominate. Brooklyn stands out as a balanced neighborhood with almost equal representation of both types.


## Listing Activity
```{r}
cat(paste("Number of listings with reviews in the past year:", sum(df$last_review > as.Date(df$latest_review) - 365, na.rm = TRUE)), "\n")
```
Out of the entire dataset, 29,118 listings have had a review in the past year. This suggests that a considerable number of listings are active and have had recent guests.

# Transform data

Convert the room_type, neighborhood_group, and neighborhood variables into factors and the last_review variable into a Date object.

```{r}

head(df)
df <- df %>%
  mutate(
    room_type = as.factor(room_type),
    neighbourhood_group = as.factor(neighbourhood_group),
    neighbourhood = as.factor(neighbourhood),
    last_review=as.Date(last_review, format = "%Y-%m-%d")
  )

str(df)

```


# Missing values

Count the number of missing values and calculate the percentage.
 
```{r}

empty_values <- c(NA, NULL, "", " ")

get_na_summary <- function(df) {
  nrows = nrow(df)
  NAs <- data.frame()

  for (column_name in colnames(df)) {
    na_count <- sum(df[[column_name]] %in% empty_values)#is.na(df[[column_name]]))
    row <- data.frame(
      variable = column_name,
      na_count = na_count,
      na_percent = round(na_count / nrows, 4) 
    )
    NAs <- rbind(NAs, row)
  }

  return(NAs)
}

get_na_summary(df)

```

Defining a function to filter out rows where variables contain missing values.
Missing values in reviews_per_month are replaced with 0, assuming no review means zero reviews per month. 
Keep only rows without empty values in the name and host_name variables.
Check the dataframe again for missing values after the cleaning.

```{r}

`%nin%` = Negate(`%in%`)

df <- df %>%
  mutate(reviews_per_month = ifelse(is.na(reviews_per_month), 0, reviews_per_month)) %>%
  filter(name %nin% empty_values) %>%
  filter(host_name %nin% empty_values)

get_na_summary(df)

```

# Feature Engineering

## Review age

Create a variable that adds the most recent review date available in the dataset and store it in latest_review.

```{r}

latest_review <- df %>%
  filter(!is.na(last_review)) %>%
  summarise(max(last_review))
latest_review <- latest_review[1,]

df <- df %>%
  mutate(
    last_review_age = latest_review - last_review,
  )

head(df)

```

## Price bin

Bin price and check the distribution across bins.

```{r}

bins <- c(0, 50, 100, 200, 500, 1000, 10000)
labels <- c("0-50", "51-100", "101-200", "201-500", "501-1000", "1001+")
df <- df %>%
  mutate(price_bin = cut(price, breaks = bins, labels = labels, include.lowest = TRUE, right = FALSE))

df %>%
  count(price_bin) %>%
  ggplot(aes(x = price_bin, y = n)) +
  geom_col() +
  labs(title="Distribution of Price Bins", x="Price Bins", y="Frequency")

```

The listings are distributed across the bins, though there is less data for the two highest price categories.
Most listings are in bins 2 and 3, i.e., between $51 and $500. The adjacent bins 1 and 4 are also well-represented.

## Name length

This adds a column to the dataframe with the count of characters in a listing's name after having removed the spaces: 

```{r}

# Count characters (without spaces)
df <- df %>%
  mutate(name_length = nchar(str_replace_all(name, " ", "")))

```


## Earnings

Create variable indicating listings average monthly earnings.

Note that we assume that every visitor leaves a review as Airbnb's reputation system
incentivizes users to do so. Note also, that we can only calculate
the lowest potential earnings as we only know the minimum number
of nights visitors need to stay.

```{r}

df <- df %>%
  mutate(lowest_monthly_earnings = minimum_nights*reviews_per_month*price)

```


## Distances

```{r}

distance <- function(lat1, long1, lat2, long2) {
  dist <- distGeo(matrix(c(lat1, long1), ncol = 2), matrix(c(lat2, long2), ncol = 2))
  return(dist/1000)
}

manhatten_distance <- function(x1, y1, x2, y2) {
  return(abs(x1 - x2) + abs(y1 - y2))  
}

```

### Distance to center of Manhattan

Create a variable that contains the distance to the "center" of New York in Manhattan, here defined as the Columbus Circle.

```{r}

center_latitude <- 40.767811385445356
center_longitude <- -73.98156481716236

```

```{r}

df <- df %>%
  mutate(
    distance_from_center = manhatten_distance(center_latitude, center_longitude, latitude, longitude)
  )

head(df)

```

### Distance to airports

Build variables with latitude and longitude of several focal points.
We use the three international airports of NY, 3 sigths (Empire State Building, Statue of Liberty, Central Park) and the five centers of every neighbourhood.

```{r}

jfk <- c(latitude = 40.6413, longitude = -73.7781) # Airport jfk
ewr <- c(latitude = 40.6895314, longitude = -74.17446239) # Airport Newark
lga <- c(latitude = 40.7769271, longitude = -73.8739659) # Airport laGuardia

```

Calculate distances between listing and focal point.

```{r}

df <- df %>%
  mutate(
    distance_to_jfk = distance(latitude, longitude, jfk[1], jfk[2]),
    distance_to_ewr = distance(latitude, longitude, ewr[1], ewr[2]),
    distance_to_lga = distance(latitude, longitude, lga[1], lga[2])
  )

```

### Distance to tourist attractions

```{r}

esb <- c(latitude = 40.748817, longitude = -73.985428) # empire state bulding
sol <- c(latitude = 40.689247, longitude = -74.044502) # statue of liberty
cp  <- c(latitude = 40.785091, longitude = -73.968285) # central park

```

```{r}

df <- df %>%
  mutate(
    distance_to_esb = distance(latitude, longitude, esb[1], esb[2]),
    distance_to_sol = distance(latitude, longitude, sol[1], sol[2]),
    distance_to_cp = distance(latitude, longitude, cp[1], cp[2])
  )

```

### Distance to neighbourhood centers

```{r}

c_mh <- c(latitude = 40.776676, longitude = -73.971321) # center Manhattan
c_br <- c(latitude = 40.650002, longitude = -73.949997) # center Brooklyn
c_si <- c(latitude = 40.579021, longitude = -74.151535) # center Staten Island
c_bx <- c(latitude = 40.837048, longitude = -73.865433) # center Bronx
c_qu <- c(latitude = 40.734470, longitude = -73.869720) # center Queens

```

```{r}

df <- df %>%
  mutate(
    distance_to_c_mh = distance(latitude, longitude, c_mh[1], c_mh[2]),
    distance_to_c_br = distance(latitude, longitude, c_br[1], c_br[2]),
    distance_to_c_bx = distance(latitude, longitude, c_bx[1], c_bx[2]),
    distance_to_c_qu = distance(latitude, longitude, c_qu[1], c_qu[2]),
    distance_to_c_si = distance(latitude, longitude, c_si[1], c_si[2])
  )
```

## Log variables

Generate kernel density estimates for each variable in the dataframe to assess their distributions.

```{r warning=FALSE, message=FALSE}

plot_distributions <- function(df) {
  plots <- lapply(names(df), function(var) {
    ggplot(df, aes(x = df[[var]])) +
      geom_density() + # You can also use geom_histogram() for histograms
      labs(title = var)
  })
  grid.arrange(grobs = plots, ncol = 2)
}

df_sample <- df %>%
  select(latitude, longitude, price, number_of_reviews, reviews_per_month, calculated_host_listings_count,  distance_from_center)

plot_distributions(df_sample)

```

Log transforme skewed distributions.

```{r warning=FALSE, message=FALSE}

df_log <- df %>%
  mutate(
    log_price = log(price),
    log_number_of_reviews = log(number_of_reviews),
    log_reviews_per_month = log(reviews_per_month),
    log_calculated_host_listings_count = log(calculated_host_listings_count)
  )

df_sample <- df_log %>%
  select(
    latitude, longitude, log_price, log_number_of_reviews, log_reviews_per_month, log_calculated_host_listings_count, distance_from_center
  )

plot_distributions(df_sample)

```

Save the modified data to the dataframe.

```{r}

df <- df_log
rm( df_log )

```

# Consistency

## Min/max

Summarize the data.

```{r}

df_numeric <- df %>%
  select(
    latitude, longitude, price, minimum_nights, number_of_reviews, last_review, reviews_per_month, 
    calculated_host_listings_count, availability_365, last_review_age, distance_from_center
  )

summary(df_numeric)

```

All numeric variables (except longitude) have non-negative values. Max for availability_365 is 365.


## Price

Price: Minimum value of 0, likely indicating missing data rather than actual free listings.
Minimum Nights: A maximum of 1250 nights suggests potential outliers.

Check entries with price equal to 0.

```{r}

df %>%
  filter(price == 0)

```

Since there are only 11 listings with a price of zero, we assume this is a data gathering error and remove the respective rows.

```{r}

df <- df %>% 
  filter(price != 0)

```

## Minimum nights

```{r}

max(df$minimum_nights)

```

The maximum for the variable minimum_nights is 1250, meaning that particular listing would have to be rented as a minimum for well over 3 years. This seems excessive as AirBnB in most cases is used for holidays or short to mid stays. We do not see a reason for a host to require the listing to be rented for such a long time and thus will consider it and similar entries as data anomalies.


```{r}

quantile(df$minimum_nights, 0.9999)

```

The minimum required nights is less than 500 for 99.99% of all listing. This number seems more or less reasonable. In the following we will therefore remove all entries that fall above this threshold.

```{r}

df <- df %>%
  filter(minimum_nights <= quantile(minimum_nights, 0.9999))

```


## Unique ids

Compare the number of rows and the number of unique ids to determine whether each row has a unique identifier.

```{r}

length_df <- nrow(df)
unique_ids <- length(unique(df$id))

length_df == unique_ids

```
There are no id inconsistencies.

## Reviews

Filter the dataframe to find entries where reviews_per_month is 0 but number_of_reviews is not 0, find entries with 0 number_of_reviews but a non-NA last_review date and identify rows where reviews_per_month is 0 but last_review is not NA.

```{r}

result <- df %>%
  filter(
    reviews_per_month == 0, 
    number_of_reviews != 0
  )

nrow(result)

result <- df %>%
  filter(
    number_of_reviews == 0,
    !is.na(last_review)
  )

nrow(result)

result <- df %>%
  filter(
    reviews_per_month == 0,
    !is.na(last_review)
  )

nrow(result)

```
All review variables are internally consistent.

# Duplicates

Find duplicates based on the id column and identify listings that are at the exact same location.

```{r}

get_duplicates_by_columns <- function(df, column_names) {
  column_indexes <- unlist(lapply(column_names, function(name) {
    return (grep(name, colnames(df)))
  })) 
  
  return (df[duplicated(df[,column_indexes]) | duplicated(df[,column_indexes], fromLast = TRUE),])
}

```

## Duplicate ids

```{r}

nrow(get_duplicates_by_columns(df, c("id")))

```
## Duplicate names

```{r}

get_duplicates_by_columns(df, c("name")) %>%
  select(id, name, host_name, neighbourhood, price) %>%
  arrange(desc(name)) %>%
  head(10)

```
There are a lot of duplicate names in the dataset. Most of the time these listings seem to be from the same host. However, the listings seem to always differ in the neighbourhood or in the price. This will be further analysed in the following.

```{r}

get_duplicates_by_columns(df, c("name", "latitude", "longitude")) %>%
  select(id, name, host_name, price, latitude, longitude) %>%
  arrange(desc(name))

```

As one can see there are no listings with the same name that are also at the same geographic position. Since the combination of name, latitude and longitude is already a super key differentiating every row, no furher supersets of this combination need to be analysed.

## Duplicate positions

```{r}

get_duplicates_by_columns(df, c("longitude", "latitude")) %>%
  select(id, name, host_name, longitude, latitude) %>%
  arrange(desc(latitude)) %>%
  head(10)

```
There are some listings that are at the exact same position. However, they more often than not have a different host or name and in every case a different price. Thus, we will not drop these entries and consider them in our analysis.

# Export

```{r}

write.csv(df, "./data/airbnb_clean.csv")

```



# General analysis

## Correlation matrix

To get an overview of the data, explore correlations between variables.

```{r}
# Correlation table with p-values
correlation_data <- df[, c("price", "minimum_nights", "number_of_reviews", 
                           "reviews_per_month", "name_length",
                           "calculated_host_listings_count", "availability_365")]

result <- rcorr(as.matrix(correlation_data))
result$r  # correlation matrix
result$P  # p-values

# Calculate the correlation matrix
cor_matrix <- cor(correlation_data, use = "complete.obs")

# Visualize the correlation matrix using corrplot
corrplot(cor_matrix, method = "color", type = "upper", 
         title = "Correlation Matrix", mar = c(0,0,1,0))

```
All correlations are significant except name_length correlated with minimum_nights and number_of_reviews.

Price:
Exhibits only weak correlations. The slight negative association with number_of_reviews (-0.048) could signal that affordability may marginally boost popularity. Minimal positive correlations are seen with name_length (0.042) and calculated_host_listings_count (0.057), pointing toward  influences on pricing through strategic naming or a host's experience. There is also a small positive link with availability_365 (0.082).

Minimum Nights:
An inverse relationship is noted with number_of_reviews (-0.082) and reviews_per_month (-0.123). This could be due to these apartments having less turnover or being less popular to rent. Positive relationships with availability_365 (0.146) and calculated_host_listings_count (0.131).

Number of Reviews:
The positive correlation with availability_365 (0.172) implies that properties with higher availability tend to garner more reviews. A subtle positive relationship with name_length (0.087), indicating greater popularity of these apartments.

Name Length:
The positive correlation with calculated_host_listings_count (0.152) could indicate that more experienced hosts might employ more detailed names for their listings.

Host Listings Count:
The positive association with availability_365 (0.226) proposes that hosts with a higher listing count tend to offer listings with higher availability. They may be less likely to use their apartments privately, thereby being able to offer them for rent more frequently.


Examine correlations divided by neighborhood.

```{r}
unique_groups <- unique(df$neighbourhood_group)

for (group in unique_groups) {
  
  subset_df <- df[df$neighbourhood_group == group,]
  
  # Subset the data to include only relevant numeric variables
  correlation_data <- subset_df[, c("price", "minimum_nights", "number_of_reviews", 
                                    "reviews_per_month", "name_length",
                                    "calculated_host_listings_count", "availability_365")]

  # Calculate the correlation matrix for the subset
  cor_matrix <- cor(correlation_data, use = "complete.obs")
  
  # Visualize the correlation matrix using corrplot
  corrplot(cor_matrix, method = "color", type = "upper", 
           title = paste("Correlation Matrix for", group), mar = c(0,0,1,0))
}

```

Price:
Notably negative correlation with number_of_reviews especially in Manhattan and Staten Island; positive correlation with name_length only in Manhattan. A nuanced relationship with calculated_host_listings_count across neighborhoods; consistent slight positive with availability, strongest in Manhattan.
    
Minimum Nights:
Uniformly negative correlation with number_of_reviews and reviews_per_month; positive with availability across regions. Generally maintains a positive relationship with calculated_host_listings_count, barring Staten Island.

Number of Reviews:
A consistent positive correlation between number_of_reviews and availability is observed across all neighborhood groups, reaffirming that heightened availability may foster increased reviews. A mild negative correlation with calculated_host_listings_count persists generally, with Staten Island being an exception.

Name Length:
The positive correlation between name_length and calculated_host_listings_count is generally upheld, albeit with Brooklyn diverging from this trend, suggesting variations in naming strategies among hosts with multiple listings.

Calculated Host Listings Count:
A consistent positive relationship with availability across all neighborhoods indicates that hosts with multiple listings might offer increased availability across their properties.

Notably, Manhattan and Staten Island occasionally diverge from a general trend.


## Number of listings by area

```{r}

ggplot(df, aes(x=longitude, y=latitude)) + 
  geom_density_2d_filled(show.legend = TRUE, aes(fill = ..level..)) + 
  coord_cartesian(xlim = c(-74.08, -73.85), ylim = c(40.64, 40.86)) + 
  labs(title="Density Heatmap of Listings", x="Longitude", y="Latitude") + 
  theme_minimal()

# Bar plot to see which neighborhood groups have the most listings:

df %>% 
  filter(!is.na(neighbourhood_group)) %>% 
  ggplot(aes(x = neighbourhood_group)) + 
  geom_bar() + 
  labs(
    title = "Listings by Neighbourhood Group", 
    x = "Neighbourhood Group", 
    y = "Frequency"
  )

```

Most listings in the dataset are in Manhattan and Brooklyn.


## Room types

```{r}
# Distribution of Room Type
df %>% 
  filter(!is.na(neighbourhood_group)) %>% 
  ggplot(aes(x=room_type)) + 
  geom_bar() + 
  labs(title="Distribution of Room Types", x="Room Type", y="Frequency")

# Room Types by Location
df %>% 
  filter(!is.na(neighbourhood_group)) %>% 
  ggplot(aes(x=neighbourhood_group, fill=room_type)) + 
  geom_bar(position="dodge") +
  labs(title="Distribution of Room Types by Neighbourhood Group", 
       x="Neighborhood", y="Frequency")

# Geographic distribution of private room vs. apartment
df %>% 
  filter(room_type %in% c('Private room', 'Entire home/apt')) %>% 
  ggplot(aes(x = longitude, y = latitude, color = room_type)) + 
  geom_point() + 
  scale_color_manual(values = c("Private room" = "blue", "Entire home/apt" = "red")) +
  labs(title = "Geographic Distribution of 'Private Room' vs. 'Entire home/apt'",
       x = "Longitude", 
       y = "Latitude",
       color = "Room Type")

# Price by Room Type
df %>%
  filter(!is.na(log_price) & !is.na(room_type)) %>%
  ggplot(aes(x = room_type, y = log_price)) +
  geom_boxplot() +
  labs(title = "Boxplot of Price vs. Room Type",
       x = "Room Type",
       y = "Log Price")

#Price bins by Room Type
ggplot(df, aes(x=price_bin, fill=room_type)) +
  geom_bar(position="dodge") +   # Use "stack" for a stacked bar plot
  labs(title="Price Bins per Room Type", 
       x="Price Bins", 
       y="Count")

```
Only few listing are for a shared room.

In Manhattan, most listings are for an entire home/apartment, while in other neighborhoods, private rooms dominate. Brooklyn stands out as a balanced neighborhood with almost equal representation of both types.

Listings for an entire home/apt tend to be more expensive, followed by private and shared rooms.


## Price and Location

```{r}
df %>% 
  filter(!is.na(price_bin)) %>% 
  ggplot(aes(x=price_bin)) +
    geom_bar() +
    labs(title="Distribution of Price Bins", x="Price Bins", y="Frequency") +
    facet_wrap(~neighbourhood_group, scales = "free_y")

# Boxplot: Price vs. Neighbourhood Group
df %>%
  filter(!is.na(log_price) & !is.na(neighbourhood_group)) %>%
  ggplot(aes(x = neighbourhood_group, y = log_price)) +
  geom_boxplot() +
  labs(title = "Boxplot of Price vs. Neighbourhood Group",
       x = "Neighbourhood Group",
       y = "Log Price")

# Geographic distribution of price bins
df %>% 
  filter(!is.na(price_bin)) %>% 
  ggplot(aes(x=longitude, y=latitude, color=price_bin)) +
    geom_point(alpha=0.5) +
    scale_color_brewer(palette="Set2") +
    labs(title="Geographic Distribution of Price Bins",
         x="Longitude",
         y="Latitude")

# Geographic distribution of log_price
ggplot(df, aes(x=longitude, y=latitude)) + 
  geom_point(aes(color=log_price), alpha=0.5) +
  scale_color_viridis_c(option = "viridis") +
  labs(title="Heatmap of Prices", x="Longitude", y="Latitude")

```
In the Manhattan area, the majority of listings are priced between $101-200, followed by listings in the $201-500 range. Notably, there are very few listings in the $0-50 price range compared to the other neighborhood groups. Queens predominantly features listings in the $51-100 price range, complemented by a significant number of listings priced between $0-50. Brooklyn has both a lot of 101-200 and 51-100 listings. Note the different scales on the y axis.

Manhattan appears to have the highest median log price among the five neighbourhood groups. It also has the most variability in log prices. Manhattan and Brooklyn also have several outliers, indicating some extremely high-priced listings. Brooklyn and Queens seem to have roughly similar median log prices, though Brooklyn's is slightly higher. Bronx and Staten Island have the lowest median log prices.

Manhattan and Brooklyn seem to be slightly right-skewed, as the whisker on the upper side is longer than the one on the lower side. Bronx, Queens, and Staten Island are more symmetric, as their boxes and whiskers are relatively evenly spread around the median.

The area further to the southwest displays a higher concentration of listings in the $0-50 range. Listings with a price range of $501-1000 are sparsely distributed, with a majority found towards the south, east, and north regions.
    
In southern Manhattan, the predominant hue is green, indicating the steepest prices. Surrounding regions also reflect elevated pricing, demonstrating a gradient effect. As we traverse Brooklyn and Queens, the intensity of green diminishes but remains brighter proximate to Manhattan. Venturing further to the east, north, or south reveals a decline in the average price, signified by progressively more dark green/blue shades.

Since the variation between neighborhoods is high, analyses should be performed separately or they may be confounded by neighborhood_group.

### Distance from center

```{r}
cor_price_distance <- cor.test(df$log_price, df$distance_from_center, method = "pearson")
print(paste("Correlation between log price and distance from center: ", cor_price_distance$estimate))

# Scatter Plot: Price vs. Distance from Center
ggplot(df, aes(x = distance_from_center, y = log_price)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +
  labs(title = "Scatter Plot of Price vs. Distance from Center",
       x = "Distance from Center",
       y = "Log Price")

```

The correlation coefficient of -0.4604 suggests a moderate negative relationship.

# Listing Names Analysis

Plot the number of characters in a name histogram using bins of size 10: 

```{r}
# Create bin labels
bin_labels = seq(0, max(df$name_length), 10)
labels <- paste0("  ",bin_labels, "-", bin_labels + 9, "  ")

#Create histogram
df %>%
  ggplot( mapping = aes( x=name_length )) +
  geom_histogram(binwidth = 10)  +
  stat_bin(
    binwidth = 10,
    geom = 'text',
    aes(label = after_stat(count)),
    vjust = -0.5,
    size = 3,
    color = "black"
  ) +
  labs( title = "How long are the names of AirBnB listings?",
        x = "Number of characters in listing's name", 
        y = "Frequency") +
  scale_x_continuous(breaks = bin_labels, labels=labels) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

While there are a few outliers (which we look at below), most names fall between 15 and 59 characters.

Let's look at the top ten percent longest names (>42) and the shortest ten percent (<20): 

```{r}
quantile(df$name_length, 0.10)
quantile(df$name_length, 0.90)
df %>% 
  filter(name_length > 42) %>%
  head(5)
df %>% 
  filter(name_length < 20) %>%
  head(5)
```

Shorter names are often not very informational, while the longer names have almost too much information. 
It could make sense to categorize the length into three bins, based on the quantiles calculated above. 


Make length of name into a factor (short, medium, long): 

```{r}
# Create three categories for the length of a name and assign a category to each listing
df <- df %>% 
  mutate(name_category = cut(name_length, 
                        breaks = c(0, 20, 42, 151),
                        labels = c("short", "medium", "long"),
                        include.lowest = TRUE)) %>% mutate(name_category = as.factor(name_category))
```

Now we look at a listing's name length and the number of reviews a listing receives per month: 

```{r warning=FALSE, message=FALSE}
# Create a basic boxplot
ggplot(df, aes(x = name_category, y = log_reviews_per_month)) +
  geom_boxplot() +
  labs(
    title = "Reviews per month by length of name",
    x = "Length of name",
    y = "Reviews per month"
  )
```

All three boxplots look very similar.


## Upper Case Letters

Another aspect that might be worth investigating is the use of upper case letters. Manual screening showed that there are some names that only consist of upper case letters which can be perceived as "screaming" on the internet. 

We now identify those listings and then introduce a new categorical (factor) variable that indicates whether a name consists of only upper case letters (1) or not (0):

```{r}
# Count the number of uppercase characters in each name
df$upper_case_count <-str_count(df$name, "[A-Z]")
# Create a new variable is_upper_case if upper_case_count is the same as the name_length
df <- df %>% mutate(is_upper_case = ifelse(name_length == upper_case_count, 1, 0)) %>% mutate(is_upper_case = as.factor(is_upper_case))
df %>% filter(is_upper_case == 1) %>% count()
```

There are 538 listings where the name contains upper case letters only. 

## Language

An initial look at the data showed that there are some listings in languages other than English. Let's detect them and see if there is any correlation to other variables.

```{r}
# Detect and assign a language
df <- df %>% mutate(name_language = detect_language(text = name)) 
# Count the occurences and order them by frequency 
df %>% count(name_language) %>% arrange(desc(n))
```

38 different languages (37 and NA) were detected, with the vase majority of listings being English. For now, we concentrate on the differentiation between English and not English.

For this, we create another variable: 

```{r}
# Replace N/A values for the next operation 
df$name_language <- df$name_language %>% replace_na('')
# Create a new variable (factor) that shows whether the language of listing is English or not
df <- df %>% mutate(is_english = ifelse(name_language == "en", 1, 0)) %>% mutate(is_english = as.factor(is_english))
```
Now we look at the semantics of the names. For this, we transform the names by, removing upper case letters, punctuation and stoppwords. 
Then, we get the most common words used in the listing's names and create a word cloud.

```{r warning=FALSE, message=FALSE}
# Create a Corpus
text <- Corpus(VectorSource(df$name))

# Convert all characters to lowercase, remove punctuation and common English stopwords (e.g., "and", "the", "of")
text <- tm_map(text, content_transformer(tolower))
text <- tm_map(text, removePunctuation)
text <- tm_map(text, removeWords, stopwords("en"))

# Create a term-document matrix
# Rows represent terms (words) and columns represent individual entries from df$name. The values in the matrix indicate the frequency of a term in a given document.
tdm <- TermDocumentMatrix(text)

# Calculate word frequencies, sorted in decreasing order
m <- as.matrix(tdm)
word_freqs <- sort(rowSums(m), decreasing=TRUE) 

# Create a data frame with two columns: word (the terms or words) and freq (their respective frequencies)
dm <- data.frame(word = names(word_freqs), freq = word_freqs)

# Create a basic wordcloud
wordcloud(words=dm$word, freq=dm$freq, min.freq=1, max.words=150, random.order=FALSE)
```


Color the most commonly used words by sentiment: 

```{r}
# Get sentiments from the bing lexicon
sentiments <- get_sentiments("bing") 

# Join the sentiments with the words 
result <- dm %>%
  left_join(sentiments, by="word") 

# Assign a color to each sentiment
top_150 <- result %>% 
  mutate(sentiment = ifelse(is.na(sentiment), "neutral", sentiment)) %>% 
  mutate(color = ifelse(sentiment == "positive", "green", 
                       ifelse(sentiment == "negative", "red", "grey"))) %>% slice(1:150) 

# Create a colored wordcloud
wordcloud(words=top_150$word, freq=top_150$freq, min.freq=1, max.words=150, random.order=FALSE, colors=top_150$color)
```

```{r}

# Clear workspace
rm( text )
rm( m )
rm( dm )

```


# Host Analysis

```{r}
results <- df %>%
  group_by(host_id) %>%
  count(host_name) %>%
  ungroup() %>%
  arrange(desc(n)) 

top_hosts <- unique(df[df$calculated_host_listings_count > 50, c("host_name", "host_id", "calculated_host_listings_count")])

top_hosts %>%
  ggplot(mapping = aes(x = host_name, y = calculated_host_listings_count)) +
  geom_bar(stat = "identity") +
  labs(title = "Top Hosts with Calculated Listings Count > 50", x = "Host Name", y = "Calculated Listings Count") +
   theme(axis.text.x = element_text(angle = 45, hjust = 1))

quantile(df$calculated_host_listings_count, 0.95)
```

Only 5% of listings have more than 15 listings. With this, 15 listings seem as reasonable a threshold as any to distinguish between hosts who rent on Airbnb professionally and those who do not. We've binned them into two groups (professional/casual) and compared the price (log), number of reviews (log), reviews per month (log) using box plots.

```{r warning=FALSE, message=FALSE}
df <- df %>% 
  mutate(host_category = cut(calculated_host_listings_count, 
                        breaks = c(0, 15, max(calculated_host_listings_count)),
                        labels = c("professional", "casual"),
                        include.lowest = TRUE)) %>% mutate(host_category = as.factor(host_category))


ggplot(df, aes(x = host_category, y = log_price)) +
  geom_boxplot() +
  labs(
    title = "Price by Host Group",
    x = "Host Group",
    y = "Price"
  )

ggplot(df, aes(x = host_category, y = log_reviews_per_month)) +
  geom_boxplot() +
  labs(
    title = "Reviews per month by Host Group",
    x = "Host Group",
    y = "Revies per Month"
  )

ggplot(df, aes(x = host_category, y = log_number_of_reviews)) +
  geom_boxplot() +
  labs(
    title = "Number of Reviews by Host Group",
    x = "Host Group",
    y = "Number of Reviews"
  )

ggplot(df, aes(x = host_category, y = log(lowest_monthly_earnings))) +
  geom_boxplot() +
  labs(
    title = "Lowest monthly earnings by Host Group",
    x = "Host Group",
    y = "Lowest monthly earnings"
  )

```

By looking at the data, it seems that sometimes multiple hosts are behind one host_id. There are various ways to identify them. We assume that there is more than one host, if one of the following appears in a host name: "+" , "/", " and ", "&". To make sure we do not include names like "Andrea",  we search for " and " with leading and trailing spaces.

```{r}
# Adds logical column that indicates whether name contains " and ", "+", "/" or "&" ; ignore.case makes sure that all variations of " and " are covered
df$is_more_than_one_host <- grepl(" and |&|\\+|/", df$host_name, ignore.case = TRUE)
# Adds column that contains vector of all names if is_more_than_one_host is true (more than one host)
df$host_names_all <- ifelse(df$is_more_than_one_host == TRUE, strsplit(df$host_name, "(?i) and |&| & |\\+| \\+ |/| / ", perl=TRUE), c(""))
# Count rows where this is the case
nrow(df[df$host_names_all != '', ])
```

Short look at how many distinct hosts this is: 

```{r}
df %>% filter(is_more_than_one_host == TRUE) %>% summarise(count = n_distinct(host_id))
```
There are 1229 distinct host_ids.

## Gender Analysis

Given the availability of host names, it might be insightful to look at the gender of the hosts and how the gender relates to other variables. 
We will use the gender package (https://github.com/lmullen/gender) to assign a gender classification to each host name. 
The package uses data from the Social Security Administration, the U.S. Census Bureau (via IPUMS USA), and the North Atlantic Population Project. 
We are aware that this approach and therefore the results from this whole section can only be of limited significance and should only be taken as indicator that this might be something worth investigating.

Before we do this, we need to split the values in the column that contains all names and create a row for each name:  

```{r}
# Add a new column called "x", filter for all values in "host_names_all" where the list contains more than one value (meaning more than one host) and use unnest to make a separate row for each name in "host_names_all" then rename "host_names_all" to "host_names_splitted" and call "x" "host_name_all" instead
df <- df %>% mutate(x = host_names_all) %>% filter(lengths(host_names_all) > 0) %>% 
  unnest(host_names_all) %>% rename(host_names_splitted = host_names_all) %>% rename(host_names_all = x)
# Add names where empty to splitted column so the original is untouched
df$host_names_splitted[!df$is_more_than_one_host] <- df$host_name[!df$is_more_than_one_host]
# Ensure df stays a data drame
df <- as.data.frame(df)
df %>% head(10)
```


Now we can assign the sex/gender to each name, using the "gender" package mentioned above. We do this in chunks, to speed up the process. 

```{r}
chunksize <- 100 
# Two temporary variables 
min <- 1
max <- 100
# Create temporary dataframe
gender <- data.frame()
for(i in 1:ceiling(nrow(df)/chunksize)){
  # Check if max is higher than the number of rows in the dataframe to make sure slicing in next line works correctly
  max <- ifelse(max>nrow(df), nrow(df), max)
  # Select next 100 rows
  row_slice_100 <- df[min:max,]
  # Use gender function to assign gender
  host_names_100_gender <- gender(row_slice_100$host_names_splitted, year=2010, method="ssa")
  # Rename the name column that was automatically created by the function gender to make sure it can be joined in the next line and remove duplicate columns
  host_names_100_gender <- host_names_100_gender %>% rename(host_names_splitted = name) %>% distinct(host_names_splitted, .keep_all = TRUE)
  # Join the results from the use of the gender function with the slice of the data frame and drop columns that were automatically added by the function "gender" 
  host_names_gender <- row_slice_100 %>% left_join(host_names_100_gender, by = "host_names_splitted") %>%  dplyr::select(-c(proportion_male, proportion_female, year_min, year_max))
  
  # Add 100 to min and max to select next 100 rows in next iteration
  min <- min+100
  max <- max+100
  # Add rows to temporary df gender
  gender <- rbind(gender, host_names_gender)
}
# Assign gender to df and make sure it is a data frame
df <- as.data.frame(gender)

# Remove all temporary used variables and the temporary data frame
rm(gender, min, max, chunksize, i, row_slice_100, host_names_100_gender, host_names_gender)

df$gender <- as.factor(df$gender)
```

Let's see if there are hosts with even more than two names by counting all the names associated with a listing id:

```{r}
df <- df %>%
  group_by(id) %>%
  mutate(host_count = n()) %>%
  as.data.frame()

max(df$host_count)
```

There seems to be a few listings with more than even two hosts. Looking at the data there is one with 4 hosts and one with 3. 


We now take a closer look at the "combined" hosts. We only want to assign one gender per host_id, so that we have the same number of rows as in the original dataset. This means we want to categorize into three categories: male, female, mixed.

```{r}
# Create temporary data frame and filter for rows where there is more than one host and then group by host_id and check if gender values are the same and assign the right value
result_df <- df %>%
  filter(is_more_than_one_host == TRUE) %>%
  group_by(host_id) %>%
  summarise(result = if (length(unique(gender)) == 1) unique(gender) else "mixed")

# Merge the result back into the original data frame
df <- left_join(df, result_df, by = "host_id")
df <- df %>%
  mutate(gender = case_when(
    !is.na(result) ~ result,
    TRUE ~ gender  # Keep the original value when the condition is not met
  )) %>% dplyr::select(-c(host_names_splitted, result)) %>% distinct(.keep_all =  TRUE)

rm(result_df)
```


We will now take a look at the gender distribution of the listings in our dataset. Note that hosts can appear more than once. 

```{r}
# Counts by gender
gender_counts <- df %>%
  group_by(gender) %>%
  summarise(count = n())

# Dum of all entries
total_count <- sum(gender_counts$count)

# Creates a pie chart
ggplot(gender_counts, aes(x = "", y = count, fill = gender)) +
  geom_bar(stat = "identity") +
  coord_polar("y") +
  labs(title = "Gender Distribution") +
  theme_void() + 
  geom_text(aes(label = paste0(gender, "\n", count, " (", scales::percent(count / total_count), ")")), 
            position = position_stack(vjust = 0.5))

# Remove help variables and dfs 
rm(gender_counts, total_count)
```

We can see a slight overrepresentation of female names, but with 20% of the names remaining unidentified this has only limited significance.

# Earnings analysis

## Data Exploration

Examine summary statistics including range, and overview distribution of earnings

```{r}

# gather summary statistics
summary(df$lowest_monthly_earnings)

max(df$lowest_monthly_earnings) - min(df$lowest_monthly_earnings)

#draw histogram of monthly earnings
df %>%
  ggplot(aes(lowest_monthly_earnings)) +
  geom_histogram() +
  scale_y_continuous()

```

As the distribution is extremely skewed to the right (median is 124.7, while range is 202783.7), we conduct a log-transformation.


```{r}

# log-transform earnings
df <- df %>%
  mutate(log_earnings = log(lowest_monthly_earnings))

# check for infinite values and how they correlate to original earnings variable
inf_earnings <- df %>%
  filter(is.infinite(log_earnings)) %>%
  select(log_earnings, lowest_monthly_earnings)

summary(inf_earnings$lowest_monthly_earnings)

inf_earnings %>%
  summarise(mean_earnings = mean(lowest_monthly_earnings),
            count = n())


```

After log-transformation, 10029 observations have been assigned infinite values.
This is, because their lowest monthly earnings are 0.
To further investigate the earnings distribution, we exclude these listings.

```{r}

# filter out observations with 0 earnings
earnings_df <- df %>%
  filter(lowest_monthly_earnings > 0)

```

We calculate basic and additional summary statistics to display the distribution in a meaningful way.

```{r}
# store summary statistics of earnings distribution
# estimate upper whisker
IQR <- IQR(earnings_df$log_earnings)
calc_upper_whisker <- (quantile(earnings_df$log_earnings, probs = 0.75) + IQR*1.5)
select_upper_whisker <- earnings_df$log_earnings >= calc_upper_whisker
upper_whisker <- earnings_df$log_earnings[select_upper_whisker]
upper_whisker <- min(upper_whisker)

# estimate lower whisker
calc_lower_whisker <- (quantile(earnings_df$log_earnings, probs = 0.25) - IQR*1.5)
select_lower_whisker <- earnings_df$log_earnings <= calc_lower_whisker
lower_whisker <- earnings_df$log_earnings[select_lower_whisker]
lower_whisker <- max(lower_whisker)

# upper and lower quantile and median
earnings_distribution <- c(
  min(earnings_df$log_earnings), 
  quantile(earnings_df$log_earnings, probs = c(0.25, 0.5, 0.75)),
  max(earnings_df$log_earnings)
)

#draw histogram
earnings_df %>%
  ggplot(aes(x = log_earnings)) +
  geom_histogram() +
  labs(title="Earnings Distribution") +
  xlab("Logged Earnings") +
  ylab("Frequency") 

# draw boxplot showing delogged values
earnings_df %>%
  ggplot(aes(y = log_earnings)) +
  geom_boxplot() +
  stat_boxplot(geom = "errorbar") +
  scale_y_continuous(breaks = c(earnings_distribution, lower_whisker, upper_whisker), 
                     labels = as.integer(exp(c(earnings_distribution, lower_whisker, upper_whisker)))) +
  scale_x_continuous(breaks = NULL, labels = NULL) +
  labs(
    y = "Lowerst Monthly Earnings (De-Logged)",
    title = "Earnings Distribution"
  )

# violin plot by neighbourhood groups
earnings_df %>%
  ggplot(aes(x = reorder(neighbourhood_group, +lowest_monthly_earnings), y = log_earnings)) +
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75), trim = TRUE) +
  labs(
    title = "Monthly Earnings Distribution by Neighbourhood Group",
    y = "Logged Lowest Monthly Earnings",
    x = NULL
  )

```

The histogram shows that the distribution of monthly earnings is approximately normally distributed. We continue to see, however, that more listings belong to the lower half of the distribution.

50% of listings earned up to 225 per month. 75% of listings earned up to 612 per month.
The Interquantile-Range corresponds to 550. Particularly, the middle half of the distribution earned between 62 and 612 per month.
There is much more variance in monthly earnings in the upper 25% of the distribution.
Excluding outliers, the range between the weakest and strongest earning listing in the upper 25% of the distribution is 18738.
As seen in the original boxplot, some outliers have extremely high earnings, with the maximal earning per month being 202783.
Considering providing an Airbnb listing a form of income, the highest percentiles of the distribution seem to account for a very high inequality in earnings. 

The violin plots convey, that there is less variance in monthly earnings in the Bronx and Staten Island and that Brooklyn and Manhattan account for the abovementioned outliers.

We will now calculate the lowest monthly earnings of NYC as a whole.

```{r}

# sort data based on earnings
earnings_df <- earnings_df[order(earnings_df$lowest_monthly_earnings), ]

# Calculate cumulative earnings
earnings_df$cumulative_earnings <- cumsum(earnings_df$lowest_monthly_earnings)

# view NYC's monthly earnings
cumulated_earnings <- max(earnings_df$cumulative_earnings)
cumulated_earnings

```

Cumulating the lowest monthly earnings of Airbnbs in New York since 2011, the whole city earns at least 25.793.569 per month.

Taking the identified skewness as a point of departure, we will investigate the shares, the parts of the distribution have on this sum.

```{r}

# cut total monthly earnings in half
cumulated_earnings_0.5 <- cumulated_earnings / 2
cumulated_earnings_0.5

# identify percentile at which cumulated monthly earnings are equal
q_earnings_halfcut <- ecdf(earnings_df$cumulative_earnings)(cumulated_earnings_0.5)
q_earnings_halfcut

```

The percentile at which the cumulative monthly earnings of both halfs is equal is approximately 0.94

```{r}

# create vector indicating position in earnings distribution
q_value_halfcut <- quantile(earnings_df$lowest_monthly_earnings, probs = q_earnings_halfcut)
quantile_indicator <- ifelse(earnings_df$lowest_monthly_earnings > q_value_halfcut , "upper 6%", "lower 94%")
earnings_df <- cbind(earnings_df, quantile_indicator)

```

Having done the calculation, we continue with description.
We draw a piechart.

```{r}

# prepare data for plotting
earningsplot_df <- earnings_df %>%
  group_by(quantile_indicator) %>%
  summarise(
    tot_earnings_mio = (sum(lowest_monthly_earnings)/1000000),
    mean_earnings = mean(lowest_monthly_earnings),
    mean_price = mean(price),
    mean_monthly_reviews = mean(reviews_per_month),
    mean_min_nights = mean(minimum_nights),
    mean_review_count = mean(number_of_reviews),
    mean_review_age = mean(last_review_age),
    count = n()
    )

# draw piechart
earningsplot_df %>%
  ggplot(aes(x = "", y = tot_earnings_mio, fill = quantile_indicator)) +
  geom_bar(stat = "identity",
           show.legend = FALSE) +
  coord_polar("y") +
  labs(title = "Cumulative Monthly Earnings of upper 6% and lower 94%") +
  theme_void() + 
  geom_text(aes(label = paste0(quantile_indicator, "\n",
                               sprintf("%.1f", tot_earnings_mio), " Mio",
                               "\n", "n = ", count)), 
            position = position_stack(vjust = 0.5)
            )

```

We also want to (in general terms at least) identify what is causing the high earnings.
Thus, we look at mean statistics on earnings-determining variables.

```{r}

# prepare data for table comparison
earningstable_df <- earningsplot_df %>%
    column_to_rownames(var = "quantile_indicator")
earningstable_df$mean_review_age <- as.numeric(earningstable_df$mean_review_age)
earningstable_df <- t(earningstable_df)
earningstable_df <- as.data.frame(earningstable_df)
earningstable_df$`lower 94%` <- as.numeric(earningstable_df$`lower 94%`)
earningstable_df$`upper 6%` <- as.numeric(earningstable_df$`upper 6%`)
earningstable_df <- earningstable_df %>%
  mutate(q6_relative_to_q94 = `upper 6%` / `lower 94%`)
earningstable_df <- round(earningstable_df, 2)

# create statistics table
rownames(earningstable_df) <- c("Lowest Monthly Earnings",
                                "Mean Monthly Earnings",   
                                "Mean Price",
                                "Mean Monthly Reviews",
                                "Mean Minimum Nights",
                                "Mean Review Count",
                                "Mean Age of Last Review",
                                "n")
colnames(earningstable_df) <- c("lower 94%",
                                "upper 6%",
                                "Proportion")
earningstable <- knitr::kable(earningstable_df, 
      caption = "Statistics on Monthly Earnings Distribution Shares", )
earningstable

```

Accumulated, the highest 6% in the earnings distribution earn as much as the 96% below them.
Expressed in total numbers, the highest-performing 2388 listings generated monthly earnings equal to the remaining 36417 listings. 

Examining average characteristics determining earnings conveys that hosts may profit from a high utilization rate.
To be more precise, although the price of highest-performing listings is 2.6 times higher compared to the average price of the remaining listings, price alone may not explain the drastic difference in monthly earnings. Rather, it is the combination of price and utilization indicators that cause higher earnings. On average, a listing of the highest-performing share in the distribution entertains almost twice as much visitors per month, and has had 1.5 times more visitors in total, while visitors are required to stay 4.4 times as long. In addition, for an average high-performing listing, only 81 days have past since the last review, whereas for an average listing of the remaining share 289 days have past. Thus, we may assume that that a listing in the highest 6% of the monthly earnings distribution has less gaps between visitors, resulting in a higher occupation rate.

As we end the analysis of earnings, we clean up the workspace.

```{r warning=FALSE, message=FALSE}

# clear workspace
rm(inf_earnings,
   earnings_df,
   IQR,
   calc_upper_whisker,
   select_upper_whisker,
   upper_whisker,
   calc_lower_whisker,
   select_lower_whisker,
   lower_whisker,
   earnings_distribution,
   cumulated_earnings,
   cumulated_earnings_0.5,
   q_earnings_halfcut,
   q_value_halfcut,
   quantile_indicator,
   earningsplot_df,
   earningstable_df,
   earningstable,
   inf_earnings,
   earnings_df,
   IQR,
   calc_upper_whisker,
   select_upper_whisker,
   upper_whisker,
   calc_lower_whisker,
   select_lower_whisker,
   lower_whisker,
   earnings_distribution,
   cumulated_earnings,
   cumulated_earnings_0.5,
   q_earnings_halfcut,
   q_value_halfcut,
   quantile_indicator,
   earningsplot_df,
   earningstable_df,
   earningstable
)

```


# Geographic analysis

## Distances

First we want to observe the correlation between price per night and the distance to the biggest airport jfk.
```{r}

plot(df$distance_to_jfk, df$price)

```
Since their are a few outliers in price, we can either use the variable log_price or use the 99pct quartil of the variable price. 
Furthermore there seem to be listings > 30km away from jfk. Those will be removed as well.
```{r}

price_pct99 <- quantile(df$price, probs = 0.99)

#create new dataframe where outliers are removed
df_2 <- df %>% filter(price < price_pct99) %>% filter(distance_to_jfk < 30)

```

```{r}

plot(df_2$distance_to_jfk, df_2$price)

```
Now we want to proceed with a linear regression.
```{r}
lin_model_jfk <- lm(price ~ distance_to_jfk, data = df_2)
summary(lin_model_jfk)

plot(df_2$distance_to_jfk, df_2$price, xlab = "Distance to JFK (in kilometers)", ylab = "Price per night (in $)", main = "Regression anaylsis (distance to JFK vs price per night)")
abline(lin_model_jfk, col = "red")
```
A significant correlation between distance to JFK and price per night (ppn) can be observed. The ppn increases around 7$ with every kilometer distance, c.p.. This result is intuitve since apartments around the airport i.e. airport hotels are always cheaper. Furthermore apartments nearer to the airport could be less expensive due to external factors like the noise of planes. 
In further discussions can be observed, if the outliers > 30km away from JFK could have a negative impact on the price, i.e. these apartments are to far away from center points of NY.

Now we conclued with the same anaylsis, but for all three airports.
```{r}
lin_model_airports <- lm(price ~ distance_to_jfk + distance_to_ewr + distance_to_lga, data = df_2)
summary(lin_model_airports)
```
Lets check for correlation between the price and the distance to NY sights.
```{r}
lin_model_sights <- lm(price ~ distance_to_esb + distance_to_sol + distance_to_cp, data = df_2)
summary(lin_model_sights)
```
The impact of sights is always significant. The estimate for esb is negative which is intuitve, because in the surounding area the rent is high, which leads to higher ppn in the listed airbnbs. Moving away from the center has therefore negative impact on prices. 

```{r}
lin_model_c_mh <- lm(price ~ distance_to_c_mh, data = df_2)
summary(lin_model_c_mh)

plot(df_2$distance_to_c_mh, df_2$price, xlab = "Distance to center Manhattan (in kilometers)", ylab = "Price per night (in $)", main = "Regression anaylsis (distance to center Manhattan vs price per night)")
abline(lin_model_c_mh, col = "red")
```
This result was quite obvious, since center Manhattan and Empire State Building nearly have the same latitude/longitude.

```{r}
lin_model_c_bx <- lm(price ~ distance_to_c_bx, data = df_2)
summary(lin_model_c_bx)

plot(df_2$distance_to_c_bx, df_2$price, xlab = "Distance to center Bronx (in kilometers)", ylab = "Price per night (in $)", main = "Regression anaylsis (distance to center Bronx vs price per night)")
abline(lin_model_c_bx, col = "red")
```
This shows the opposite result: Closer to the center of Bronx has lower price per night. Again, this is what we would expect from earlier analysis and from our intuition, since Bronx is not that close to the center. Also other negative aspects related to Bronx neighborhood could lead to this correlation.

```{r}

rm( df_2 )

```


## Neighbourhood group distribution

```{r}

neighbourhood_group_counts <- df %>%
  count(neighbourhood_group)

# dataframe containing population of every neighbourhood group in new york (data represents 2020 population)
population_df <- data.frame(
  neighbourhood_group = c("Manhattan", "Brooklyn", "Queens", "Staten Island", "Bronx"),
  population = c(1600000, 2500000, 2271000, 475000, 1427000)
)

# dataframe containing area of every neighbourhood group in new york
area_df <- data.frame(
  neighbourhood_group = c("Manhattan", "Brooklyn", "Queens", "Staten Island", "Bronx"),
  area = c(59, 180, 280, 152, 110)
)

# creates pie chart showing partition of listings across neighbourhood groups
listing_count_pie_chart <- ggplot(neighbourhood_group_counts, aes(x = "", y = n, fill = neighbourhood_group)) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar("y", start = 0) +
    ggtitle("Number of listings per neighbourhood group") +
    theme_void()

# creates pie chart showing partition of population across neighbourhood group
population_pie_chart <- ggplot(population_df, aes(x = "", y = population, fill = neighbourhood_group)) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar("y", start = 0) +
    ggtitle("Population per neighbourhood groups") +
    theme_void()

# creates pie chart showing partition of area across neighbourhood group
area_pie_chart <- ggplot(area_df, aes(x = "", y = area, fill = neighbourhood_group)) +
    geom_bar(stat = "identity", width = 1) +
    coord_polar("y", start = 0) +
    ggtitle("Area per neighbourhood groups") +
    theme_void()

# collect plots in list
plots <- list(
  listing_count_pie_chart,
  population_pie_chart,
  area_pie_chart
)

# arrange plots in grid
grid.arrange(grobs = plots, padding = 2, ncol = 2)

```
The pie charts above show the partition of listings, population and area across every neighbourhood group respectively. As one can see there are certain differences in distribution. While Manhattan holds a large portion of listings it makes up a considerably smaller portion in terms of population and especially area. On the other side the contrary pattern can be observed for Queens, as it holds a large portion of the population and area while making up a considerably smaller portion of listing. In summary it seems that Manhattan capacity in terms of area and population is already used up to a large extend considering the amount of housing listed in it, while Queens might offer opportunities for additional listings as it holds a large area and population.

## Most expensive neighbourhoods

This section will focus on the different neighbourhood groups and identifying the most expensive neighbourhoods within these groups.

```{r warning=FALSE, message=FALSE}

# function to plot bar chart with the most expensive neighbourhoods in a given neighbourhood group
get_most_expensive_neighbourhoods_in_group <- function(group) {
  
  # select most expensive neighbourhoods in the given group by order by price
  # this is needed for ordering the following plot
  most_expensive_neighbourhoods <- df %>%
    filter(neighbourhood_group == group) %>%
    group_by(neighbourhood) %>%
    summarise(sum_price = sum(price)) %>%
    arrange(desc(sum_price))
  
  # plot most expensive neighbourhoods in a bar chart
  df %>%
    filter(neighbourhood_group == group) %>%
    group_by(neighbourhood, room_type) %>%
    summarise(sum_price = sum(price)) %>%
    arrange(match(neighbourhood, most_expensive_neighbourhoods$neighbourhood)) %>%
    mutate(neighbourhood = as.factor(neighbourhood)) %>%
    head(20) %>%
    ggplot(mapping = aes(x = factor(neighbourhood, level = most_expensive_neighbourhoods$neighbourhood), y = sum_price, fill = room_type)) +
    geom_col(stat = "identity") +
    labs(
      title = paste("Most expensive neighbourhoods in", group),
      x = "Neighbourhood",
      y = "Price in $"
    )
}

```

### Queens

```{r warning=FALSE, message=FALSE}

get_most_expensive_neighbourhoods_in_group("Queens")

```

Above one can see the seven most expensive neighbourhoods in Queens. Each bar represents one neighbourhood and the respective cummalitve price, sectioned into the three different room types. Astoria holds the largest share in terms of price with a fairly equal share in private room and entire homes. The high prices in Astonia could be explained by its short distance to Manhattan and closeness to many tourist attraction and other vocal points. 

### Manhattan

```{r warning=FALSE, message=FALSE}

get_most_expensive_neighbourhoods_in_group("Manhattan")

```

The distribution for Manhattan looks quite different. Instead of one neighbourhood making up the majority of the price density most of the top seven neighbourhood are in a similar range. Furthermore one can see that all of the neighbourhoods are more expensive than Astoria with a cummulative price of over one million for each neighbourhood. Another interesting insight is that most of the price density seems to originate from listing offering entire houses. This is in contrast to Queens that showed a more equal distribution. Most likely the listings labeled as "Entire home/apt" consist mostly of appartement due to the layout of Manhattan with its many skyscrapers. However, this is just an assumption and for future research we would recommend differentiating between homes and appartements and add respective room types. The higher mass for entire homes/appartements could indicate that entire appartments or homes are just proportionally more expensive than private rooms in Manhattan compared to Queens. 

## Geographic Listing density

This section will focus on the location and geographic density of listings by plotting them on a OpenStreetMap.

```{r}

# Define different icons to be used for the map
icon_width <- 30
icon_height <- 30
icon_base_url <- "https://img.icons8.com/?size=2x&format=png&id="

statue_of_liberty_icon <- makeIcon(
  iconUrl = paste(icon_base_url, 4674),
  iconWidth = icon_width, iconHeight = icon_height
)

skyscraper_icon <- makeIcon(
  iconUrl = paste(icon_base_url, "cGbCkzI99Cf8"),
  iconWidth = icon_width, iconHeight = icon_height
)

park_icon <- makeIcon(
  iconUrl = paste(icon_base_url, "2410"),
  iconWidth = icon_width, iconHeight = icon_height
)

times_square_icon <- makeIcon(
  iconUrl = paste(icon_base_url, "swhOdQ9tCaEq"),
  iconWidth = icon_width, iconHeight = icon_height
)

bridge_icon <- makeIcon(
  iconUrl = paste(icon_base_url, "pJmt_hefPAkD"),
  iconWidth = icon_width, iconHeight = icon_height
)

museum_icon <- makeIcon(
  iconUrl = paste(icon_base_url, "3496"),
  iconWidth = icon_width, iconHeight = icon_height
)

monument_icon <- makeIcon(
  iconUrl = paste(icon_base_url, "4703"),
  iconWidth = icon_width, iconHeight = icon_height
)

college_icon <- makeIcon(
  iconUrl = paste(icon_base_url, "11173"),
  iconWidth = icon_width, iconHeight = icon_height
)

stadium_icon <- makeIcon(
  iconUrl = paste(icon_base_url, "JlLTMd4NfTIp"),
  iconWidth = icon_width, iconHeight = icon_height
)

airport_icon <- makeIcon(
  iconUrl = paste(icon_base_url, "3683"),
  iconWidth = icon_width, iconHeight = icon_height
) 

ferry_icon <- makeIcon(
  iconUrl = paste(icon_base_url, "PLcwTvSptrJJ"),
  iconWidth = icon_width, iconHeight = icon_height
)

room_type_icons <- iconList(
  "Private room" = makeIcon(
    iconUrl = paste(icon_base_url, "BBsnsTkuoCkC"),
    iconWidth = icon_width, iconHeight = icon_height
  ),
  "Entire home/apt" = makeIcon(
    iconUrl = paste(icon_base_url, "Uc54oOGCsjOE"),
    iconWidth = icon_width, iconHeight = icon_height
  ),
  "Shared room" = makeIcon(
    iconUrl = paste(icon_base_url, "46791"),
    iconWidth = icon_width, iconHeight = icon_height
  )
)

```


```{r}

# function for plotting a given dataframe on a OpenStreeMap using leaflet
# parameters: zoom (integer) controls how zoomed in the map initially is; ratio (float) controls how density is displayed, lower ratio => less value needed for high density; showMarkers (boolean) controls wether markers should be shown or not
plot_map <- function (df, zoom, ratio, showMarkers) {
  
  # take center of mass of dataframe
  center_lng <- (df %>% summarise(mean(longitude)))[1, 1]
  center_lat <- (df %>% summarise(mean(latitude)))[1, 1]
  
  map_max <- nrow(df) * ratio
  
  base_map <- df %>%
    leaflet() %>%
    addTiles() %>%
    addProviderTiles(providers$OpenStreetMap.DE) %>%
    setView(center_lng, center_lat, zoom) %>%
    addHeatmap(lng = ~longitude, lat = ~latitude, max = map_max, radius = 20, blur = 10)
  
  if (showMarkers)
    return(
      base_map %>%
        addMarkers(lat = 40.6897, lng = -74.0445, label = "Statue of Liberty", icon = statue_of_liberty_icon) %>%
        addMarkers(lat = 40.7484, lng = -73.9856, label = "Empire State Building", icon = skyscraper_icon) %>%
        addMarkers(lat = 40.7826, lng = -73.9655, label = "Central Park", icon = park_icon) %>%
        addMarkers(lat = 40.7579, lng = -73.9855, label = "Times Square", icon = times_square_icon) %>%
        addMarkers(lat = 40.7061, lng = -73.9967, label = "Brooklyn Bridge", icon = bridge_icon) %>%
        addMarkers(lat = 40.7188, lng = -73.9900, label = "Tenement Museum", icon = museum_icon) %>%
        addMarkers(lat = 40.7794, lng = -73.9632, label = "Metropolitan Museum of Art", icon = museum_icon) %>%
        addMarkers(lat = 40.7029, lng = -74.0153, label = "The Battery", icon = park_icon) %>%
        addMarkers(lat = 40.7074, lng = -73.9907, label = "Manhattan Bridge", icon = bridge_icon) %>%
        addMarkers(lat = 40.7136, lng = -73.9719, label = "Williamsburg Bridge", icon = bridge_icon) %>%
        addMarkers(lat = 40.7129, lng = -74.0132, label = "One World Observatory", icon = skyscraper_icon) %>%
        addMarkers(lat = 40.7129, lng = -74.0132, label = "Stonewall National Monument", icon = monument_icon) %>%
        addMarkers(lat = 40.7421, lng = -73.9879, label = "Madison Square Park", icon = park_icon) %>%
        addMarkers(lat = 40.7468, lng = -73.9582, label = "Gantry Plaza State Park", icon = park_icon) %>%
        addMarkers(lat = 40.8971, lng = -73.8862, label = "Van Cortlandt Park", icon = park_icon) %>%
        addMarkers(lat = 40.8655, lng = -73.8943, label = "Edgar Allan Poe Cottage", icon = monument_icon) %>%
        addMarkers(lat = 40.8729, lng = -73.8945, label = "Lehman College, CUNY", icon = college_icon) %>%
        addMarkers(lat = 40.8774, lng = -73.8794, label = "The Museum of Bronx History", icon = museum_icon) %>%
        addMarkers(lat = 40.8295, lng = -73.9262, label = "Yankee Stadium", icon = stadium_icon) %>%
        addMarkers(lat = 40.7563, lng = -73.9240, label = "Museum of the Moving Image", icon = museum_icon) %>%
        addMarkers(lat = 40.7767, lng = -73.8739, label = "LaGuardia Airport", icon = airport_icon) %>%
        addMarkers(lat = 40.7438, lng = -73.9351, label = "LaGuardia Community College", icon = college_icon) %>%
        addMarkers(lat = 40.6467, lng = -74.0765, label = "The Staten Island September 11th Memorial", icon = monument_icon) %>%
        addMarkers(lat = 40.6454, lng = -74.0822, label = "Curtis High School", icon = college_icon) %>%
        addMarkers(lat = 40.6436, lng = -74.0719, label = "Staten Island Ferry", icon = ferry_icon) %>%
        addMarkers(lat = 40.7022, lng = -73.9958, label = "Brooklyn Bridge Park", icon = park_icon) %>%
        addMarkers(lat = 40.6711, lng = -73.9637, label = "Brooklyn Museum", icon = museum_icon) %>%
        addMarkers(lat = 40.6913, lng = -73.9752, label = "Fort Greene Park", icon = park_icon)
    )
  
  base_map
}

```


```{r}

plot_map(df, zoom = 10, ratio = 0.05, showMarkers = F)

```

The above map shows the density of listings across the entire city. A red/orange color indicates a high number of listings in that area while a blue color indicates a low density of listings. As one would expect the concentration is higher towards the center of the city and low on the outer edges. Manhattan and northern Brooklyn hold the main hot-spots in terms of listings. While there are dominant spots in the city holding most listings, one can also see that there are listing all over the city offering stays for all parts of New York. In the context of market segmentation it could be beneficial to have a more spread out offer over a bigger area of the city. In that case the above map holds valuable information considering less occupied parts of the city and could be used for identifying them. Since the map shows the offer that AirBnB generates in the city, one can also derive where the most effective spots to generate demand might be. In terms of physical marketing in the city, we would recommend focusing on the areas with high density such as lower Manhattan and upper Brooklyn. Additionally, we would recommend prioritizing listings from these areas in the recommendation system of the app and website, to increase the chances of users finding a suitable listing in a short time. Nevertheless, this map just shows a rough overview over the entire city. For a more detailed analysis we will, in the following, consider every respective neighbourhood group of the city.

### Manhattan

```{r}

manhattan <- df %>%
  filter(neighbourhood_group == "Manhattan")

plot_map(manhattan, 11.5, ratio = 0.02, showMarkers = T)

```

As previous analysis showed Manhattan is the most critical neighbourhood group in the dataset. It is the most popular in terms of listings and also contains the most expensive listings. The above map shows a more detailed view on it. As one can see there are two main hot spots, one located towards the south of the district and one close to Times Square. The one close to Times Square could be explained due to its distance to Central Park, Times Square and other central points. The high density towards lower Manhattan could be explained by the higher frequency of normal apartment buildings and rooms which most likely build the center of mass for the listings. Furthermore, this specific part of Manhattan allows a short access to Williamsburg, Brooklyn and Manhattan - Bridge, connecting guests to Brooklyn and other parts of the city. When it comes to guest targeting to visit a wide range of attractions throughout New York, this part of Manhattan might offer a interesting alternative to the more expensive listings in central Manhattan.

### Brooklyn

```{r}

brooklyn <- df %>%
  filter(neighbourhood_group == "Brooklyn")

plot_map(brooklyn, 12, ratio = 0.02, showMarkers = T)

```

As we have seen on the overview map north Brooklyn represents one of the bigger hotspots in the city. Here, a similar pattern as with lower Manhattan can be observed. This district offers a wide area and normal apartment buildings for guests, while still keeping close access to Manhattan through Williamsburg Bridge. It appears that a fairly larger group of guests are willing to sacrifice a very close distance to central Manhattan for more reasonable prices and also better access to other districts of the city. AirBnB should prioritize these choke points like North Brooklyn as they offer a high potential for additional listing, due to the larger population and area. In comparison it seems that Manhattan has used up a high degree of its potential offerings.

### Bronx

```{r}

bronx <- df %>%
  filter(neighbourhood_group == "Bronx")

plot_map(bronx, 11.5, ratio = 0.01, showMarkers = T)

```

The Bronx is located to the north of Manhattan. While it offers somewhat close access to the aforementioned hotspots in Manhattan, it is also isolated from the rest of the city. Due to this, the most popular areas in the Bronx are located to the south and near the Yankee stadium. There could also be a group of guest that specifically rent out listings for nigt stays after a Yankee games. To stimulate this group, we would suggest promoting the listings which can be seen close to the Yankee Stadium on game days.

### Queens

```{r}

queens <- df %>%
  filter(neighbourhood_group == "Queens")

plot_map(queens, 11.5, ratio = 0.02, showMarkers = T)

```

Queens is the biggest neighbourhood group in terms of area. The map above shows that a very small range of the potential are in Queens is actually occupied with listings. Most listings are grouped up towards the north of Queens, close to Queensboro Bridge. Furthermore, Queens offers a close access to LaGuardia airport which is also benefitial to the average AirBnB guest.

### Staten Island

```{r}

staten_island <- df %>%
  filter(neighbourhood_group == "Staten Island")

plot_map(staten_island, 12, ratio = 0.05, showMarkers = T)

```

Staten Island offers the smallest amount of listings in the dataset. Similarly, to Queens a large amount of its area remains unused for listings. While their is a harbour offering a ferry to Manhattan and other parts of the city, this mode of transportation is probably not suitable for the average trip through the city due to its cost and speed. We would recommend, giving an overall lower priority to this neighbourhood group when it comes to user recommendations, unless a specific interest in the access to the New York Bay can be deternined.

## Geographic distribution of room types

While the previous maps have shown the density of listings throughout the city, they did not offer further information regarding the listing, such as its room type and other relevant information. This section attempts to address these shortcomings and analyse further geographical patterns.

```{r}

# plots a cluster map which groups observations together in distinct areas and labels them with the count of observations in that area
plot_cluster_map <- function(df, zoom) {
  center_lng <- (df %>% summarise(mean(longitude)))[1, 1]
  center_lat <- (df %>% summarise(mean(latitude)))[1, 1]
    
  df %>%
    leaflet() %>%
    addTiles() %>%
    addProviderTiles(providers$OpenStreetMap.DE) %>%
    setView(center_lng, center_lat, zoom) %>%
    addMarkers(lng = ~longitude, lat = ~latitude, clusterOptions = markerClusterOptions(), label = ~name)
}

```

### Private room

```{r}

private_room <- df %>%
  filter(room_type == "Private room")

plot_cluster_map(private_room, 10)

```

The above map shows the distribution of observations listed as private rooms in the dataset. When hovering over the counts, one can see the area that is being considered for the aggregation and when zoomed in, singular listings can be observed with their respective names. Similar to previous results, one can see that the highest grouping of listing is in the area of Manhattan and northern Brooklyn. Especially in norther Brooklyn close to Williamsburg Bridge a lot of private rooms are offered. As this coincides with the distribution we observed in the previous chapter in Brooklyn, this further supports the suspicion that a high amount of apartment building are located in that area, that allow such a high offer. As this seems to be one of the most critical points of AirBnB operations in the city next to Manhattan, we would suggest sponsoring the activity in this area with marketing and through recommendations in the app and website.

### Entire home

```{r}

entire_home <- df %>%
  filter(room_type == "Entire home/apt")

plot_cluster_map(entire_home, 10)

```

The picture of listings counting entire homes and apartements offers a similar but slightly different result. While the main hotspot is always lower Manhattan and northern Brooklyn this time the center of mass is located in lower Manhattan instead of Brooklyn. This is somewhat surprising to us as Brooklyn offers a wider area and one would expect a larger offer of entire apartments or buildings there instead of Manhattan which has a smaller area. We would recommend investigating this area of northern Brooklyn more and identifying why the distribution in comparison to private rooms is shifted so much. As a result one might be able to detect neighbourhoods that offer potential for additional listings in the category of entire apartments or buildings. This could also generate additional listings close to Manhattan that are in a lower price range, leading to a potentially more diversified market and more guests.

### Shared room

```{r}

shared_room <- df %>%
  filter(room_type == "Shared room")

plot_cluster_map(shared_room, 10)

```

The general distribution of shared rooms does not differ much from the one of other room types. It seems that in general listings of every type are present throughout every area of the city and and a sufficient diversity exists in that regard to satisfy most guests. An interesting observation we would like to point out in the above map is the high number of shared rooms close to Times Square on 9th avenue crossing 51st St. We would recommend further investigating why there are over 60 listings of private rooms in that specific area as it might hold insights for the preferences of host of such housing.

## Other interesting maps

In this section we target to shed light on geographical insights that could not be explored in the previous sections due to the type of map used. For this reason we employ a map which maps out every single observation with its own icon on the map. Observations with a green icon showing a room indicate listing of the type "Private room", listings of the type "Entire house/app" are indicated with a red and yellow house. Lastly, private rooms are shown with a 

```{r}

# plots the observations in the given data frame on a map by showing a marker for each observation, where the icon of the marker corresponds to the room type of the observation
plot_room_type_map <- function(df, zoom) {
  center_lng <- (df %>% summarise(mean(longitude)))[1, 1]
  center_lat <- (df %>% summarise(mean(latitude)))[1, 1]
    
  df %>%
    leaflet() %>%
    addTiles() %>%
    addProviderTiles(providers$OpenStreetMap.DE) %>%
    setView(center_lng, center_lat, zoom) %>%
    addMarkers(
      lng = ~longitude, 
      lat = ~latitude, 
      icon = ~room_type_icons[room_type], 
      label = ~name,
      popup = ~paste(sep = "<br/>",
        paste("<b>", name, "</b>"),
        paste("Price: ", price, "$"),
        paste("#Reviews: ", number_of_reviews),
        paste("Review age: ", last_review_age, "days"),
        paste("Availability: ", availability_365, "days"),
        paste("Host name: ", host_name)
      )
    )
}

```

### Highest earnings

```{r}

plot_room_type_map(
  df %>% 
    arrange(desc(lowest_monthly_earnings)) %>% 
    head(50),
  11
)

```

Above one can see the top 50 listings in terms of lowest monthly earnings. The most noticeable aspect of this map is that most of these listings are entire houses or apartments. Furthermore, most of them are located in lower Manahattan with some scarce listings towards central Manhattan. When considering the profit of AirBnB these are the highest value listings. The goal should be to transform every other listings to be more like these ones. Since we have seen that lower Manhattan already contains a large number of listings, we would recommend to focus less on the creation of new listings in that area and focus more on improving its quality. For this we would recommend conducting surveys with the host of the listing seen above and inquire about what makes their listings so successful and applying this feedback for listings in the same area.  The listings located further away from the center are especially interesting as these areas have a lower concentration of listings. For these areas we would recommend focusing on creating new listing opportunities through marketing and communication with potential listing providers. We would also recommend contacting hosts of listings such as e.g. "The St. Johns: A 5-Bedroom Townhouse Near the Park" and inquire whether they have additional rooms or apartments they would be willing to rent out.

### Highest review

```{r}

highest_review <- df %>%
  arrange(desc(number_of_reviews)) %>%
  head(50)
  
plot_room_type_map(
  highest_review, 
  11
)

```

This map shows the 100 listings with the highest number of reviews in the dataset. While similar clusters to previous analysis can be seen, an interesting pattern are the two groups close to the LaGuardia and JFK airport. It seems that guest are very adamant about leaving reviews for accommodations near the airport. Furthermore, this might indicate that these listings are booked very often and thus represent an important income stream for AirBnb. As there is a low density of listings in both of these areas as can be seen in previous heatmaps, these areas could present an opportunity for additional high value listings.

### Cheap listings with high reviews

```{r}

plot_room_type_map(
  df %>% 
    filter(price_bin == "0-50") %>% 
    arrange(desc(number_of_reviews)) %>% 
    head(300), 
  11
)

```

Cheap listings have been disregarded a little throughout this analysis. An interesting cluster of cheap listings are those that also hold a high number of reviews. Such listings can be seen above. The first striking aspect of this map is that in contrast to the listings with the highest earnings, one can identify way more private and shared room listings. These are most likely listings offered for tourist that have a short stay in the city and do not have a reason to commit to an entire apartment or house. Most of the listings of this type are located in brooklyn and near the airports LaGuardia and JFK. While these listings might not be the most valuable in the dataset, we would still recommend including them in the strategy for AirBnB as they make up a steady income stream.
